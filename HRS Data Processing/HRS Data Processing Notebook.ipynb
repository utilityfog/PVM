{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3d9e05-172f-4c83-9deb-a25a6a039113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (4711, 55) \n",
      " \n",
      " Columns of data: Index(['Unnamed: 0', 'hhidpn', 'wave', 'mstat', 'cendiv', 'gender', 'rahispan',\n",
      "       'raracem', 'iwbeg', 'dage_m', 'dage_y', 'raedyrs', 'rarelig', 'ravetrn',\n",
      "       'agey_m', 'shlt', 'shltc', 'depres', 'effort', 'sleepr', 'cesd', 'bmi',\n",
      "       'smokev', 'smoken', 'drinkn', 'hibp', 'diab', 'cancr', 'lung', 'heart',\n",
      "       'strok', 'psych', 'arthr', 'conde', 'cogtot', 'slfmem', 'pstmem',\n",
      "       'spcfac', 'hsptim', 'puff', 'puffpos', 'timwlk', 'hatotb', 'iearn',\n",
      "       'isret', 'covs', 'hiltc', 'lbrf', 'logiearn', 'logisret', 'loghspti',\n",
      "       'loghatotb', 'id', 'nt', 'n2'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hhidpn</th>\n",
       "      <th>wave</th>\n",
       "      <th>mstat</th>\n",
       "      <th>cendiv</th>\n",
       "      <th>gender</th>\n",
       "      <th>rahispan</th>\n",
       "      <th>raracem</th>\n",
       "      <th>iwbeg</th>\n",
       "      <th>dage_m</th>\n",
       "      <th>dage_y</th>\n",
       "      <th>raedyrs</th>\n",
       "      <th>rarelig</th>\n",
       "      <th>ravetrn</th>\n",
       "      <th>agey_m</th>\n",
       "      <th>shlt</th>\n",
       "      <th>shltc</th>\n",
       "      <th>depres</th>\n",
       "      <th>effort</th>\n",
       "      <th>sleepr</th>\n",
       "      <th>cesd</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smokev</th>\n",
       "      <th>smoken</th>\n",
       "      <th>drinkn</th>\n",
       "      <th>hibp</th>\n",
       "      <th>diab</th>\n",
       "      <th>cancr</th>\n",
       "      <th>lung</th>\n",
       "      <th>heart</th>\n",
       "      <th>strok</th>\n",
       "      <th>psych</th>\n",
       "      <th>arthr</th>\n",
       "      <th>conde</th>\n",
       "      <th>cogtot</th>\n",
       "      <th>slfmem</th>\n",
       "      <th>pstmem</th>\n",
       "      <th>spcfac</th>\n",
       "      <th>hsptim</th>\n",
       "      <th>puff</th>\n",
       "      <th>puffpos</th>\n",
       "      <th>timwlk</th>\n",
       "      <th>hatotb</th>\n",
       "      <th>iearn</th>\n",
       "      <th>isret</th>\n",
       "      <th>covs</th>\n",
       "      <th>hiltc</th>\n",
       "      <th>lbrf</th>\n",
       "      <th>logiearn</th>\n",
       "      <th>logisret</th>\n",
       "      <th>loghspti</th>\n",
       "      <th>loghatotb</th>\n",
       "      <th>id</th>\n",
       "      <th>nt</th>\n",
       "      <th>n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3010</td>\n",
       "      <td>3</td>\n",
       "      <td>1.married</td>\n",
       "      <td>9.pacific</td>\n",
       "      <td>1.male</td>\n",
       "      <td>0.not hispanic</td>\n",
       "      <td>1.white/caucasian</td>\n",
       "      <td>13345</td>\n",
       "      <td>931</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>1.protestant</td>\n",
       "      <td>0.no</td>\n",
       "      <td>60</td>\n",
       "      <td>3.good</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>3</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>4.fair</td>\n",
       "      <td>2.same</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490500.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>4.partly retired</td>\n",
       "      <td>8.294049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.103181</td>\n",
       "      <td>2</td>\n",
       "      <td>123702</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3010</td>\n",
       "      <td>6</td>\n",
       "      <td>1.married</td>\n",
       "      <td>9.pacific</td>\n",
       "      <td>1.male</td>\n",
       "      <td>0.not hispanic</td>\n",
       "      <td>1.white/caucasian</td>\n",
       "      <td>15445</td>\n",
       "      <td>931</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>1.protestant</td>\n",
       "      <td>0.no</td>\n",
       "      <td>66</td>\n",
       "      <td>3.good</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1</td>\n",
       "      <td>28.299999</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>3.good</td>\n",
       "      <td>2.same</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>704000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>13728.0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>4.partly retired</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>9.527193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.464534</td>\n",
       "      <td>3</td>\n",
       "      <td>123702</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3010</td>\n",
       "      <td>7</td>\n",
       "      <td>1.married</td>\n",
       "      <td>9.pacific</td>\n",
       "      <td>1.male</td>\n",
       "      <td>0.not hispanic</td>\n",
       "      <td>1.white/caucasian</td>\n",
       "      <td>16267</td>\n",
       "      <td>931</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>1.protestant</td>\n",
       "      <td>0.no</td>\n",
       "      <td>68</td>\n",
       "      <td>3.good</td>\n",
       "      <td>0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>3.good</td>\n",
       "      <td>2.same</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>15600.0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>4.partly retired</td>\n",
       "      <td>8.699514</td>\n",
       "      <td>9.655026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.535797</td>\n",
       "      <td>4</td>\n",
       "      <td>123702</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3010</td>\n",
       "      <td>8</td>\n",
       "      <td>1.married</td>\n",
       "      <td>9.pacific</td>\n",
       "      <td>1.male</td>\n",
       "      <td>0.not hispanic</td>\n",
       "      <td>1.white/caucasian</td>\n",
       "      <td>16875</td>\n",
       "      <td>931</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>1.protestant</td>\n",
       "      <td>0.no</td>\n",
       "      <td>70</td>\n",
       "      <td>3.good</td>\n",
       "      <td>0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>27.100000</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4.fair</td>\n",
       "      <td>2.same</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1.standing</td>\n",
       "      <td>2.78</td>\n",
       "      <td>914000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14040.0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>5.retired</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.549665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.725586</td>\n",
       "      <td>5</td>\n",
       "      <td>123702</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>3010</td>\n",
       "      <td>10</td>\n",
       "      <td>1.married</td>\n",
       "      <td>9.pacific</td>\n",
       "      <td>1.male</td>\n",
       "      <td>0.not hispanic</td>\n",
       "      <td>1.white/caucasian</td>\n",
       "      <td>18520</td>\n",
       "      <td>931</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>1.protestant</td>\n",
       "      <td>0.no</td>\n",
       "      <td>74</td>\n",
       "      <td>3.good</td>\n",
       "      <td>0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.fair</td>\n",
       "      <td>3.worse</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.standing</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1240000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16644.0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>5.retired</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.719805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.030622</td>\n",
       "      <td>7</td>\n",
       "      <td>123702</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4706</th>\n",
       "      <td>13126</td>\n",
       "      <td>213435010</td>\n",
       "      <td>4</td>\n",
       "      <td>7.widowed</td>\n",
       "      <td>5.s atlantic</td>\n",
       "      <td>2.female</td>\n",
       "      <td>0.not hispanic</td>\n",
       "      <td>1.white/caucasian</td>\n",
       "      <td>14045</td>\n",
       "      <td>1082</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>2.catholic</td>\n",
       "      <td>0.no</td>\n",
       "      <td>74</td>\n",
       "      <td>3.good</td>\n",
       "      <td>.p</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>2</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3.good</td>\n",
       "      <td>2.same</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8856.0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>5.retired</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.088850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.373663</td>\n",
       "      <td>107639</td>\n",
       "      <td>123702</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>13127</td>\n",
       "      <td>213435010</td>\n",
       "      <td>5</td>\n",
       "      <td>7.widowed</td>\n",
       "      <td>5.s atlantic</td>\n",
       "      <td>2.female</td>\n",
       "      <td>0.not hispanic</td>\n",
       "      <td>1.white/caucasian</td>\n",
       "      <td>14715</td>\n",
       "      <td>1082</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>2.catholic</td>\n",
       "      <td>0.no</td>\n",
       "      <td>75</td>\n",
       "      <td>3.good</td>\n",
       "      <td>0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>25.700001</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>2</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3.good</td>\n",
       "      <td>2.same</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>5.retired</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.035987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.407565</td>\n",
       "      <td>107640</td>\n",
       "      <td>123702</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708</th>\n",
       "      <td>13128</td>\n",
       "      <td>213435010</td>\n",
       "      <td>6</td>\n",
       "      <td>7.widowed</td>\n",
       "      <td>5.s atlantic</td>\n",
       "      <td>2.female</td>\n",
       "      <td>0.not hispanic</td>\n",
       "      <td>1.white/caucasian</td>\n",
       "      <td>15475</td>\n",
       "      <td>1082</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>2.catholic</td>\n",
       "      <td>0.no</td>\n",
       "      <td>78</td>\n",
       "      <td>3.good</td>\n",
       "      <td>0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>27.100000</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>2</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3.good</td>\n",
       "      <td>3.worse</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>5.retired</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.169519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.347461</td>\n",
       "      <td>107641</td>\n",
       "      <td>123702</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4709</th>\n",
       "      <td>13129</td>\n",
       "      <td>213435010</td>\n",
       "      <td>7</td>\n",
       "      <td>7.widowed</td>\n",
       "      <td>5.s atlantic</td>\n",
       "      <td>2.female</td>\n",
       "      <td>0.not hispanic</td>\n",
       "      <td>1.white/caucasian</td>\n",
       "      <td>16206</td>\n",
       "      <td>1082</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>2.catholic</td>\n",
       "      <td>0.no</td>\n",
       "      <td>80</td>\n",
       "      <td>3.good</td>\n",
       "      <td>0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>3</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>3.good</td>\n",
       "      <td>3.worse</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9912.0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>5.retired</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.201502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.617286</td>\n",
       "      <td>107642</td>\n",
       "      <td>123702</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4710</th>\n",
       "      <td>13131</td>\n",
       "      <td>213435010</td>\n",
       "      <td>9</td>\n",
       "      <td>7.widowed</td>\n",
       "      <td>5.s atlantic</td>\n",
       "      <td>2.female</td>\n",
       "      <td>0.not hispanic</td>\n",
       "      <td>1.white/caucasian</td>\n",
       "      <td>17637</td>\n",
       "      <td>1082</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>2.catholic</td>\n",
       "      <td>0.no</td>\n",
       "      <td>83</td>\n",
       "      <td>3.good</td>\n",
       "      <td>0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>3</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>4.fair</td>\n",
       "      <td>3.worse</td>\n",
       "      <td>0.no</td>\n",
       "      <td>0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.standing</td>\n",
       "      <td>4.16</td>\n",
       "      <td>18464.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>0.no</td>\n",
       "      <td>1.yes</td>\n",
       "      <td>5.retired</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.230143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.823578</td>\n",
       "      <td>107644</td>\n",
       "      <td>123702</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4711 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     hhidpn  wave      mstat        cendiv    gender  \\\n",
       "0              1       3010     3  1.married     9.pacific    1.male   \n",
       "1              2       3010     6  1.married     9.pacific    1.male   \n",
       "2              3       3010     7  1.married     9.pacific    1.male   \n",
       "3              4       3010     8  1.married     9.pacific    1.male   \n",
       "4              6       3010    10  1.married     9.pacific    1.male   \n",
       "...          ...        ...   ...        ...           ...       ...   \n",
       "4706       13126  213435010     4  7.widowed  5.s atlantic  2.female   \n",
       "4707       13127  213435010     5  7.widowed  5.s atlantic  2.female   \n",
       "4708       13128  213435010     6  7.widowed  5.s atlantic  2.female   \n",
       "4709       13129  213435010     7  7.widowed  5.s atlantic  2.female   \n",
       "4710       13131  213435010     9  7.widowed  5.s atlantic  2.female   \n",
       "\n",
       "            rahispan            raracem  iwbeg  dage_m  dage_y raedyrs  \\\n",
       "0     0.not hispanic  1.white/caucasian  13345     931      77      12   \n",
       "1     0.not hispanic  1.white/caucasian  15445     931      77      12   \n",
       "2     0.not hispanic  1.white/caucasian  16267     931      77      12   \n",
       "3     0.not hispanic  1.white/caucasian  16875     931      77      12   \n",
       "4     0.not hispanic  1.white/caucasian  18520     931      77      12   \n",
       "...              ...                ...    ...     ...     ...     ...   \n",
       "4706  0.not hispanic  1.white/caucasian  14045    1082      90      12   \n",
       "4707  0.not hispanic  1.white/caucasian  14715    1082      90      12   \n",
       "4708  0.not hispanic  1.white/caucasian  15475    1082      90      12   \n",
       "4709  0.not hispanic  1.white/caucasian  16206    1082      90      12   \n",
       "4710  0.not hispanic  1.white/caucasian  17637    1082      90      12   \n",
       "\n",
       "           rarelig ravetrn  agey_m    shlt shltc depres effort sleepr  cesd  \\\n",
       "0     1.protestant    0.no      60  3.good    -1  1.yes  1.yes  1.yes     3   \n",
       "1     1.protestant    0.no      66  3.good    -1   0.no   0.no   0.no     1   \n",
       "2     1.protestant    0.no      68  3.good     0   0.no   0.no   0.no     0   \n",
       "3     1.protestant    0.no      70  3.good     0   0.no   0.no   0.no     0   \n",
       "4     1.protestant    0.no      74  3.good     0   0.no   0.no   0.no     0   \n",
       "...            ...     ...     ...     ...   ...    ...    ...    ...   ...   \n",
       "4706    2.catholic    0.no      74  3.good    .p   0.no   0.no   0.no     0   \n",
       "4707    2.catholic    0.no      75  3.good     0   0.no   0.no   0.no     0   \n",
       "4708    2.catholic    0.no      78  3.good     0   0.no   0.no   0.no     0   \n",
       "4709    2.catholic    0.no      80  3.good     0   0.no   0.no   0.no     0   \n",
       "4710    2.catholic    0.no      83  3.good     0   0.no   0.no   0.no     1   \n",
       "\n",
       "            bmi smokev smoken  drinkn   hibp  diab cancr  lung  heart strok  \\\n",
       "0     28.000000   0.no   0.no       1   0.no  0.no  0.no  0.no  1.yes  0.no   \n",
       "1     28.299999   0.no   0.no       0   0.no  0.no  0.no  0.no  1.yes  0.no   \n",
       "2     26.600000   0.no   0.no       0   0.no  0.no  0.no  0.no  1.yes  0.no   \n",
       "3     27.100000   0.no   0.no       0   0.no  0.no  0.no  0.no  1.yes  0.no   \n",
       "4     24.000000   0.no   0.no       0   0.no  0.no  0.no  0.no  1.yes  0.no   \n",
       "...         ...    ...    ...     ...    ...   ...   ...   ...    ...   ...   \n",
       "4706  24.900000  1.yes   0.no       2  1.yes  0.no  0.no  0.no   0.no  0.no   \n",
       "4707  25.700001  1.yes   0.no       2  1.yes  0.no  0.no  0.no   0.no  0.no   \n",
       "4708  27.100000  1.yes   0.no       2  1.yes  0.no  0.no  0.no   0.no  0.no   \n",
       "4709  25.400000  1.yes   0.no       3  1.yes  0.no  0.no  0.no   0.no  0.no   \n",
       "4710  24.900000  1.yes   0.no       3  1.yes  0.no  0.no  0.no   0.no  0.no   \n",
       "\n",
       "      psych  arthr  conde  cogtot  slfmem   pstmem spcfac  hsptim   puff  \\\n",
       "0      0.no   0.no      1      35  4.fair   2.same   0.no       0    NaN   \n",
       "1      0.no   0.no      1      31  3.good   2.same   0.no       0    NaN   \n",
       "2      0.no   0.no      1      18  3.good   2.same   0.no       0    NaN   \n",
       "3      0.no   0.no      1      20  4.fair   2.same   0.no       0  490.0   \n",
       "4      0.no   0.no      1      17  4.fair  3.worse   0.no       0  330.0   \n",
       "...     ...    ...    ...     ...     ...      ...    ...     ...    ...   \n",
       "4706   0.no   0.no      1      24  3.good   2.same   0.no       0    NaN   \n",
       "4707   0.no   0.no      1      24  3.good   2.same   0.no       0    NaN   \n",
       "4708   0.no   0.no      1      23  3.good  3.worse   0.no       1    NaN   \n",
       "4709   0.no  1.yes      2      25  3.good  3.worse   0.no       1    NaN   \n",
       "4710  1.yes  1.yes      3      21  4.fair  3.worse   0.no       0  160.0   \n",
       "\n",
       "         puffpos  timwlk     hatotb    iearn    isret   covs  hiltc  \\\n",
       "0            NaN     NaN   490500.0   4000.0      0.0  1.yes  1.yes   \n",
       "1            NaN     NaN   704000.0  10000.0  13728.0   0.no  1.yes   \n",
       "2            NaN     NaN   756000.0   6000.0  15600.0   0.no  1.yes   \n",
       "3     1.standing    2.78   914000.0      0.0  14040.0   0.no  1.yes   \n",
       "4     1.standing    3.10  1240000.0      0.0  16644.0   0.no  1.yes   \n",
       "...          ...     ...        ...      ...      ...    ...    ...   \n",
       "4706         NaN     NaN    87000.0      0.0   8856.0   0.no  1.yes   \n",
       "4707         NaN     NaN    90000.0      0.0   8400.0   0.no  1.yes   \n",
       "4708         NaN     NaN    84750.0      0.0   9600.0   0.no  1.yes   \n",
       "4709         NaN     NaN   111000.0      0.0   9912.0   0.no  1.yes   \n",
       "4710  1.standing    4.16    18464.0      0.0  10200.0   0.no  1.yes   \n",
       "\n",
       "                  lbrf  logiearn  logisret  loghspti  loghatotb      id  \\\n",
       "0     4.partly retired  8.294049  0.000000       0.0  13.103181       2   \n",
       "1     4.partly retired  9.210340  9.527193       0.0  13.464534       3   \n",
       "2     4.partly retired  8.699514  9.655026       0.0  13.535797       4   \n",
       "3            5.retired  0.000000  9.549665       0.0  13.725586       5   \n",
       "4            5.retired  0.000000  9.719805       0.0  14.030622       7   \n",
       "...                ...       ...       ...       ...        ...     ...   \n",
       "4706         5.retired  0.000000  9.088850       0.0  11.373663  107639   \n",
       "4707         5.retired  0.000000  9.035987       0.0  11.407565  107640   \n",
       "4708         5.retired  0.000000  9.169519       0.0  11.347461  107641   \n",
       "4709         5.retired  0.000000  9.201502       0.0  11.617286  107642   \n",
       "4710         5.retired  0.000000  9.230143       0.0   9.823578  107644   \n",
       "\n",
       "          nt  n2  \n",
       "0     123702   7  \n",
       "1     123702   7  \n",
       "2     123702   7  \n",
       "3     123702   7  \n",
       "4     123702   7  \n",
       "...      ...  ..  \n",
       "4706  123702   7  \n",
       "4707  123702   7  \n",
       "4708  123702   7  \n",
       "4709  123702   7  \n",
       "4710  123702   7  \n",
       "\n",
       "[4711 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "hrs = pd.read_csv(\"life_expectancy_CleanedHRSdata.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(f'Shape of data: {hrs.shape} \\n \\n Columns of data: {hrs.columns}')\n",
    "hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd58c467-353a-4645-8773-d56e504027e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### These are functions from the raw_data_processing.ipynb\n",
    "def standardize_dataframe(df, numerical_columns, exclude_columns):\n",
    "    \"\"\"\n",
    "    A function to standardize specified numerical values in a DataFrame using z-score normalization,\n",
    "    excluding specified columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas DataFrame): The input DataFrame.\n",
    "        numerical_columns (list): A list of numerical column names to standardize.\n",
    "        exclude_columns (list): A list of column names to exclude from standardization.\n",
    "        \n",
    "    Returns:\n",
    "        pandas DataFrame: A DataFrame with standardized numerical values.\n",
    "    \"\"\"\n",
    "    # Exclude columns specified in exclude_columns\n",
    "    columns_to_standardize = [col for col in numerical_columns if col not in exclude_columns]\n",
    "    \n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler to the selected columns and transform the values\n",
    "    standardized_values = scaler.fit_transform(df[columns_to_standardize])\n",
    "    \n",
    "    # Create a new DataFrame with the standardized values and the same index and columns as the original DataFrame\n",
    "    standardized_df = pd.DataFrame(standardized_values, index=df.index, columns=columns_to_standardize)\n",
    "    \n",
    "    # Combine the standardized numerical columns with non-numerical columns from the original DataFrame\n",
    "    for col in df.columns:\n",
    "        if col not in columns_to_standardize:\n",
    "            standardized_df[col] = df[col]\n",
    "    \n",
    "    return standardized_df\n",
    "\n",
    "def encode_categorical(df, categorical_vars):\n",
    "    \"\"\"\n",
    "    A function to perform one-hot encoding for categorical variables in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas DataFrame): The input DataFrame.\n",
    "        categorical_columns (list): A list of column names containing categorical variables to be one-hot encoded.\n",
    "        \n",
    "    Returns:\n",
    "        pandas DataFrame: A DataFrame with one-hot encoded categorical variables.\n",
    "    \"\"\"\n",
    "    print(f\"encodable categorical vars: {categorical_vars}\")\n",
    "    \n",
    "    # Convert numeric categorical variables to categorical type\n",
    "    for col in categorical_vars:\n",
    "        df[col] = df[col].astype('category')\n",
    "        \n",
    "    # Extract categorical variables\n",
    "    categorical_df = df[categorical_vars]\n",
    "    \n",
    "    # Perform one-hot encoding for categorical variables, drop first ensures there is no multicolinearity\n",
    "    result = pd.get_dummies(categorical_df, dtype=float, drop_first=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def replace_encoded_categorical(df, encoded_categorical_df, categorical_columns):\n",
    "    \"\"\"\n",
    "    A function to replace original categorical columns in a DataFrame with one-hot encoded columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas DataFrame): The original DataFrame.\n",
    "        encoded_categorical_df (pandas DataFrame): The DataFrame with one-hot encoded categorical variables.\n",
    "        categorical_columns (list): A list of column names containing original categorical variables.\n",
    "        \n",
    "    Returns:\n",
    "        pandas DataFrame: A DataFrame with original categorical columns replaced by one-hot encoded columns.\n",
    "    \"\"\"\n",
    "    # Drop original categorical columns from the original DataFrame\n",
    "    df = df.drop(columns=categorical_columns)\n",
    "    \n",
    "    # Concatenate the original DataFrame with the one-hot encoded DataFrame\n",
    "    df = pd.concat([df, encoded_categorical_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e882bfe-7d35-4c0a-80a1-57adc54eaa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['mstat', 'cendiv', 'gender', 'rahispan', 'raracem', 'raedyrs', 'ravetrn', 'shlt', 'shltc', 'depres', 'effort', 'sleepr', 'smokev', 'smoken', 'hibp', 'diab', 'cancr', 'lung', 'heart', 'strok', 'psych', 'arthr', 'slfmem', 'pstmem', 'spcfac', 'puffpos', 'covs', 'hiltc', 'lbrf']\n",
      "encodable categorical vars: ['mstat', 'cendiv', 'gender', 'rahispan', 'raracem', 'ravetrn', 'shlt', 'shltc', 'depres', 'effort', 'sleepr', 'smokev', 'smoken', 'hibp', 'diab', 'cancr', 'lung', 'heart', 'strok', 'psych', 'arthr', 'slfmem', 'pstmem', 'spcfac', 'puffpos', 'covs', 'hiltc', 'lbrf']\n",
      "Each hhidpn value appears only once.\n",
      "First half columns: Index(['shlt_2.very good', 'gender_2.female', 'raedyrs', 'lbrf_3.unemployed',\n",
      "       'sleepr_1.yes', 'shlt_3.good', 'hibp_1.yes', 'wave', 'slfmem_4.fair',\n",
      "       'mstat_2.married,spouse absent', 'depres_1.yes', 'cendiv_3.en central',\n",
      "       'mstat_4.separated', 'covs_1.yes', 'loghatotb', 'conde', 'dage_m',\n",
      "       'raracem_3.other', 'shlt_5.poor', 'puffpos_2.sitting',\n",
      "       'cendiv_2.mid atlantic', 'arthr_1.yes', 'shltc_0',\n",
      "       'heart_4.disp prev record and no cond', 'pstmem_2.same', 'smoken_1.yes',\n",
      "       'cancr_1.yes', 'mstat_3.partnered', 'psych_1.yes',\n",
      "       'cendiv_6.es central', 'spcfac_1.yes', 'shltc_4', 'loghspti',\n",
      "       'shltc_-2', 'hiltc_1.yes', 'cendiv_4.wn central',\n",
      "       'lbrf_4.partly retired', 'smokev_1.yes', 'cendiv_8.mountain', 'iearn',\n",
      "       'spcfac_0.no', 'lung_4.disp prev record and no cond', 'raedyrs_17plus',\n",
      "       'mstat_8.never married'],\n",
      "      dtype='object')\n",
      "Second half columns: Index(['shlt_4.fair', 'slfmem_2.very good',\n",
      "       'arthr_4.disp prev record and no cond', 'lbrf_5.retired', 'logisret',\n",
      "       'drinkn', 'shltc_-3', 'mstat_5.divorced', 'timwlk', 'diab_1.yes',\n",
      "       'shltc_-4', 'logiearn', 'lbrf_6.disabled', 'cogtot',\n",
      "       'strok_4.disp prev record and no cond', 'shltc_3', 'agey_m',\n",
      "       'pstmem_3.worse', 'slfmem_3.good', 'rahispan_1.hispanic',\n",
      "       'psych_4.disp prev record and no cond', 'bmi',\n",
      "       'raracem_2.black/african american', 'cesd', 'shltc_1', 'strok_1.yes',\n",
      "       'cendiv_7.ws central', 'puff', 'lbrf_2.works pt', 'covs_0.no',\n",
      "       'heart_1.yes', 'mstat_7.widowed', 'ravetrn_1.yes', 'hsptim',\n",
      "       'cendiv_9.pacific', 'lung_1.yes', 'effort_1.yes', 'lbrf_7.not in lbrf',\n",
      "       'cendiv_5.s atlantic', 'slfmem_5.poor', 'isret',\n",
      "       'strok_2.tia/possible stroke', 'shltc_2', 'hiltc_0.no', 'hatotb'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#columns_to_drop = ['Unnamed: 0', 'nt','n2','dage_y', 'rarelig']\n",
    "columns_to_drop = ['Unnamed: 0', 'nt','n2','dage_y', 'rarelig']\n",
    "hrs_cleaned = hrs.drop(columns=columns_to_drop, errors='ignore')\n",
    "    # Replace empty strings with NaN to handle both empty strings and NaN values uniformly\n",
    "hrs_cleaned = hrs_cleaned.replace('', np.nan)\n",
    "    \n",
    "    # Drop rows with any NaN values\n",
    "hrs_cleaned = hrs_cleaned.dropna()\n",
    "def random_sample_per_group(df, group_col):\n",
    "    \"\"\"\n",
    "    Randomly selects one observation per group from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to sample from.\n",
    "    group_col (str): The name of the column to group by.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with one randomly selected row per group.\n",
    "    \"\"\"\n",
    "    # Group by the specified column and apply the sampling\n",
    "    return df.groupby(group_col).apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
    "\n",
    "def is_categorical(df):\n",
    "    \"\"\"\n",
    "    Determines which columns in a DataFrame are categorical based on data type being a string.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas DataFrame): The DataFrame to check.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of column names that are considered categorical because they are of string type.\n",
    "    \"\"\"\n",
    "    categorical_vars = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    return categorical_vars\n",
    "\n",
    "# Determine categorical columns\n",
    "categorical_columns = is_categorical(hrs_cleaned)  # Adjust threshold as necessary\n",
    "print(\"Categorical columns:\", categorical_columns)\n",
    "# To remove columns\n",
    "categorical_columns = [col for col in categorical_columns if col not in ['raedyrs']]\n",
    "# Encode categorical variables\n",
    "encoded_df = encode_categorical(hrs_cleaned.copy(), categorical_columns)\n",
    "\n",
    "# Replace original categorical columns with encoded ones\n",
    "final_df = replace_encoded_categorical(hrs_cleaned, encoded_df, categorical_columns)\n",
    "\n",
    "# Convert all values to integers, setting '17.17+ yrs' specifically to 17\n",
    "final_df['raedyrs'] = final_df['raedyrs'].replace('17.17+ yrs', '17').astype(int)\n",
    "\n",
    "# Create a binary indicator for whether the education years are 17 and above\n",
    "final_df['raedyrs_17plus'] = (final_df['raedyrs'] >= 17).astype(int)\n",
    "\n",
    "# Check to make sure each \"hhidpn\" appears only once\n",
    "def random_sample_per_group(df, group_col):\n",
    "    \"\"\"\n",
    "    Randomly selects one observation per group from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to sample from.\n",
    "    group_col (str): The name of the column to group by.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with one randomly selected row per group.\n",
    "    \"\"\"\n",
    "    # Group by the specified column and apply the sampling\n",
    "    return df.groupby(group_col).apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
    "\n",
    "# Randomly sample one observation per individual\n",
    "final_df = random_sample_per_group(final_df, 'hhidpn')\n",
    "\n",
    "# Check to make sure each \"hhidpn\" appears only once\n",
    "def check_unique_hhidpn(sampled_df, group_col):\n",
    "    \"\"\"\n",
    "    Checks if each group identifier appears only once in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    sampled_df (pd.DataFrame): The DataFrame to check.\n",
    "    group_col (str): The name of the column to group by.\n",
    "    \"\"\"\n",
    "    if sampled_df[group_col].duplicated().any():\n",
    "        print(\"Some hhidpn values appear more than once.\")\n",
    "    else:\n",
    "        print(\"Each hhidpn value appears only once.\")\n",
    "\n",
    "# Perform the check\n",
    "check_unique_hhidpn(final_df, 'hhidpn')\n",
    "\n",
    "columns_to_drop = ['hhidpn', 'iwbeg', 'id']\n",
    "final_df = final_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "\n",
    "# Shuffle the columns randomly\n",
    "shuffled_columns = np.random.permutation(final_df.columns)\n",
    "\n",
    "# Split the columns approximately in half\n",
    "midpoint = len(shuffled_columns) // 2\n",
    "first_half_columns = shuffled_columns[:midpoint]\n",
    "second_half_columns = shuffled_columns[midpoint:]\n",
    "\n",
    "# Create two new DataFrames based on these split columns\n",
    "df_first_half = final_df[first_half_columns]\n",
    "df_second_half = final_df[second_half_columns]\n",
    "\n",
    "# Print out the columns to verify\n",
    "print(\"First half columns:\", df_first_half.columns)\n",
    "print(\"Second half columns:\", df_second_half.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
