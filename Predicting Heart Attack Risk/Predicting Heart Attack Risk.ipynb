{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd342f78-05f7-415f-9646-3263f6692695",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ray's Code for predicting heart attack risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02c24b0-6ce8-4791-acfe-5b4daee0dfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Patient ID', 'Age', 'Sex', 'Cholesterol', 'Blood Pressure',\n",
      "       'Heart Rate', 'Diabetes', 'Family History', 'Smoking', 'Obesity',\n",
      "       'Alcohol Consumption', 'Exercise Hours Per Week', 'Diet',\n",
      "       'Previous Heart Problems', 'Medication Use', 'Stress Level',\n",
      "       'Sedentary Hours Per Day', 'Income', 'BMI', 'Triglycerides',\n",
      "       'Physical Activity Days Per Week', 'Sleep Hours Per Day', 'Country',\n",
      "       'Continent', 'Hemisphere', 'Heart Attack Risk'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('heart_attack_prediction_dataset.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Print the column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ad988f-1a08-4978-9e3b-5460b36e58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class heart_attack_prediction_dataset:\n",
    "    '''\n",
    "    This class is made to work with the heart_attack_predictio_dataset.csv dataset.\n",
    "    '''\n",
    "    def load_clean(self, df_path):\n",
    "        '''\n",
    "        Load the dataset and clean it up\n",
    "        \n",
    "        CleaningDecisions:\n",
    "        1. Seperate Systolic and Diastolic blood pressure into seperate columns \n",
    "        2. Create an interaction term between systolic and diastolic.\n",
    "        3. Drop 'Sex_Male', 'Diet_Average', 'Country_Argentina' to prevent multicolinearity.\n",
    "        4. Set categorical variables to category type.\n",
    "        '''\n",
    "        \n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "\n",
    "        df = pd.read_csv('heart_attack_prediction_dataset.csv')\n",
    "        \n",
    "        # Switch income to log income.\n",
    "        Income = df['Income']\n",
    "        df['Log Income'] = np.log(Income)\n",
    "\n",
    "        # Set Categorical Variables\n",
    "        categorical_variables = ['Sex', 'Diet', 'Country']\n",
    "\n",
    "        for col in categorical_variables:\n",
    "                df[col] = df[col].astype('category')\n",
    "\n",
    "        ### One hot encode the categorical variables\n",
    "        df = pd.get_dummies(df, columns=['Sex', 'Diet','Country'])\n",
    "        # Drop to prevent multicolinearity with binary variables\n",
    "        df = df.drop(['Sex_Male', 'Diet_Average', 'Country_Argentina'], axis=1)\n",
    "\n",
    "        ### Seperate systolic and diastolic blood pressure into their own variables and create an interaction term.\n",
    "        # Split the 'Blood Pressure' column into 'Systolic' and 'Diastolic'\n",
    "        df[['Systolic', 'Diastolic']] = df['Blood Pressure'].str.split('/', expand=True).astype(int)\n",
    "\n",
    "        # Drop for no need\n",
    "        df = df.drop(['Patient ID', 'Blood Pressure', 'Income', 'Continent', 'Hemisphere'], axis=1)\n",
    "\n",
    "        # Create interaction term by multiplying Systolic and Diastolic pressures\n",
    "        df['BP_Interaction'] = df['Systolic'] * df['Diastolic']\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def normalize(self, df):\n",
    "        '''\n",
    "        Normalize the features in the dataframe.\n",
    "        '''\n",
    "        df - self.scaler.fit_transform(df)\n",
    "        return df\n",
    "        \n",
    "    def split(self, X, y):\n",
    "        '''\n",
    "        Split the data into training and testing sets.\n",
    "        '''\n",
    "        #print(list(df.columns))\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "        # Separate the target variable (y) and the features (X)\n",
    "        X = df.drop('Heart Attack Risk', axis=1)\n",
    "        y = df['Heart Attack Risk']\n",
    "\n",
    "        # Normalize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "\n",
    "        print(\"Object type of current x and y variables:\", type(X_train))\n",
    "        print(\"Shape of X_train:\", X_train.shape)\n",
    "        print(\"Shape of X_test:\", X_test.shape)\n",
    "        print(\"Shape of y_train:\", y_train.shape)\n",
    "        print(\"Shape of y_test:\", y_test.shape)\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b15415-4b50-4607-a8ae-a8e830cfb93c",
   "metadata": {},
   "source": [
    "First Clean the data.\n",
    "\n",
    "Then choose what to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b640ddb7-7a31-4f33-829f-57b3bf805e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Cholesterol', 'Heart Rate', 'Diabetes', 'Family History', 'Smoking', 'Obesity', 'Alcohol Consumption', 'Exercise Hours Per Week', 'Previous Heart Problems', 'Medication Use', 'Stress Level', 'Sedentary Hours Per Day', 'BMI', 'Triglycerides', 'Physical Activity Days Per Week', 'Sleep Hours Per Day', 'Heart Attack Risk', 'Log Income', 'Sex_Female', 'Diet_Healthy', 'Diet_Unhealthy', 'Country_Australia', 'Country_Brazil', 'Country_Canada', 'Country_China', 'Country_Colombia', 'Country_France', 'Country_Germany', 'Country_India', 'Country_Italy', 'Country_Japan', 'Country_New Zealand', 'Country_Nigeria', 'Country_South Africa', 'Country_South Korea', 'Country_Spain', 'Country_Thailand', 'Country_United Kingdom', 'Country_United States', 'Country_Vietnam', 'Systolic', 'Diastolic', 'BP_Interaction']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Family History</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Alcohol Consumption</th>\n",
       "      <th>Exercise Hours Per Week</th>\n",
       "      <th>Previous Heart Problems</th>\n",
       "      <th>Medication Use</th>\n",
       "      <th>Stress Level</th>\n",
       "      <th>Sedentary Hours Per Day</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Triglycerides</th>\n",
       "      <th>Physical Activity Days Per Week</th>\n",
       "      <th>Sleep Hours Per Day</th>\n",
       "      <th>Heart Attack Risk</th>\n",
       "      <th>Log Income</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Diet_Healthy</th>\n",
       "      <th>Diet_Unhealthy</th>\n",
       "      <th>Country_Australia</th>\n",
       "      <th>Country_Brazil</th>\n",
       "      <th>Country_Canada</th>\n",
       "      <th>Country_China</th>\n",
       "      <th>Country_Colombia</th>\n",
       "      <th>Country_France</th>\n",
       "      <th>Country_Germany</th>\n",
       "      <th>Country_India</th>\n",
       "      <th>Country_Italy</th>\n",
       "      <th>Country_Japan</th>\n",
       "      <th>Country_New Zealand</th>\n",
       "      <th>Country_Nigeria</th>\n",
       "      <th>Country_South Africa</th>\n",
       "      <th>Country_South Korea</th>\n",
       "      <th>Country_Spain</th>\n",
       "      <th>Country_Thailand</th>\n",
       "      <th>Country_United Kingdom</th>\n",
       "      <th>Country_United States</th>\n",
       "      <th>Country_Vietnam</th>\n",
       "      <th>Systolic</th>\n",
       "      <th>Diastolic</th>\n",
       "      <th>BP_Interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>208</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.168189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.615001</td>\n",
       "      <td>31.251233</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12.473822</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>88</td>\n",
       "      <td>13904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>389</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.813242</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.963459</td>\n",
       "      <td>27.194973</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12.562936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>93</td>\n",
       "      <td>15345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>324</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.078353</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9.463426</td>\n",
       "      <td>28.176571</td>\n",
       "      <td>587</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12.368540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>99</td>\n",
       "      <td>17226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>383</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.828130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7.648981</td>\n",
       "      <td>36.464704</td>\n",
       "      <td>378</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11.741176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>100</td>\n",
       "      <td>16300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>318</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.804299</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.514821</td>\n",
       "      <td>21.809144</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11.986392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>8008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>60</td>\n",
       "      <td>121</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.917342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10.806373</td>\n",
       "      <td>19.655895</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12.369126</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>76</td>\n",
       "      <td>7144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>28</td>\n",
       "      <td>120</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.558426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.833038</td>\n",
       "      <td>23.993866</td>\n",
       "      <td>617</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>12.291704</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>102</td>\n",
       "      <td>16014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>47</td>\n",
       "      <td>250</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.148438</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.375214</td>\n",
       "      <td>35.406146</td>\n",
       "      <td>527</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10.518619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>75</td>\n",
       "      <td>12075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>36</td>\n",
       "      <td>178</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.789950</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.029104</td>\n",
       "      <td>27.294020</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12.254591</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>67</td>\n",
       "      <td>7973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>25</td>\n",
       "      <td>356</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.081748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9.005234</td>\n",
       "      <td>32.914151</td>\n",
       "      <td>180</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12.418511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>67</td>\n",
       "      <td>9246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8763 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Cholesterol  Heart Rate  Diabetes  Family History  Smoking  \\\n",
       "0      67          208          72         0               0        1   \n",
       "1      21          389          98         1               1        1   \n",
       "2      21          324          72         1               0        0   \n",
       "3      84          383          73         1               1        1   \n",
       "4      66          318          93         1               1        1   \n",
       "...   ...          ...         ...       ...             ...      ...   \n",
       "8758   60          121          61         1               1        1   \n",
       "8759   28          120          73         1               0        0   \n",
       "8760   47          250         105         0               1        1   \n",
       "8761   36          178          60         1               0        1   \n",
       "8762   25          356          75         1               1        0   \n",
       "\n",
       "      Obesity  Alcohol Consumption  Exercise Hours Per Week  \\\n",
       "0           0                    0                 4.168189   \n",
       "1           1                    1                 1.813242   \n",
       "2           0                    0                 2.078353   \n",
       "3           0                    1                 9.828130   \n",
       "4           1                    0                 5.804299   \n",
       "...       ...                  ...                      ...   \n",
       "8758        0                    1                 7.917342   \n",
       "8759        1                    0                16.558426   \n",
       "8760        1                    1                 3.148438   \n",
       "8761        0                    0                 3.789950   \n",
       "8762        0                    1                18.081748   \n",
       "\n",
       "      Previous Heart Problems  Medication Use  Stress Level  \\\n",
       "0                           0               0             9   \n",
       "1                           1               0             1   \n",
       "2                           1               1             9   \n",
       "3                           1               0             9   \n",
       "4                           1               0             6   \n",
       "...                       ...             ...           ...   \n",
       "8758                        1               1             8   \n",
       "8759                        0               0             8   \n",
       "8760                        1               0             5   \n",
       "8761                        1               1             5   \n",
       "8762                        0               0             8   \n",
       "\n",
       "      Sedentary Hours Per Day        BMI  Triglycerides  \\\n",
       "0                    6.615001  31.251233            286   \n",
       "1                    4.963459  27.194973            235   \n",
       "2                    9.463426  28.176571            587   \n",
       "3                    7.648981  36.464704            378   \n",
       "4                    1.514821  21.809144            231   \n",
       "...                       ...        ...            ...   \n",
       "8758                10.806373  19.655895             67   \n",
       "8759                 3.833038  23.993866            617   \n",
       "8760                 2.375214  35.406146            527   \n",
       "8761                 0.029104  27.294020            114   \n",
       "8762                 9.005234  32.914151            180   \n",
       "\n",
       "      Physical Activity Days Per Week  Sleep Hours Per Day  Heart Attack Risk  \\\n",
       "0                                   0                    6                  0   \n",
       "1                                   1                    7                  0   \n",
       "2                                   4                    4                  0   \n",
       "3                                   3                    4                  0   \n",
       "4                                   1                    5                  0   \n",
       "...                               ...                  ...                ...   \n",
       "8758                                7                    7                  0   \n",
       "8759                                4                    9                  0   \n",
       "8760                                4                    4                  1   \n",
       "8761                                2                    8                  0   \n",
       "8762                                7                    4                  1   \n",
       "\n",
       "      Log Income  Sex_Female  Diet_Healthy  Diet_Unhealthy  Country_Australia  \\\n",
       "0      12.473822           0             0               0                  0   \n",
       "1      12.562936           0             0               1                  0   \n",
       "2      12.368540           1             1               0                  0   \n",
       "3      11.741176           0             0               0                  0   \n",
       "4      11.986392           0             0               1                  0   \n",
       "...          ...         ...           ...             ...                ...   \n",
       "8758   12.369126           0             1               0                  0   \n",
       "8759   12.291704           1             1               0                  0   \n",
       "8760   10.518619           0             0               0                  0   \n",
       "8761   12.254591           0             0               1                  0   \n",
       "8762   12.418511           1             1               0                  0   \n",
       "\n",
       "      Country_Brazil  Country_Canada  Country_China  Country_Colombia  \\\n",
       "0                  0               0              0                 0   \n",
       "1                  0               1              0                 0   \n",
       "2                  0               0              0                 0   \n",
       "3                  0               1              0                 0   \n",
       "4                  0               0              0                 0   \n",
       "...              ...             ...            ...               ...   \n",
       "8758               0               0              0                 0   \n",
       "8759               0               1              0                 0   \n",
       "8760               1               0              0                 0   \n",
       "8761               1               0              0                 0   \n",
       "8762               0               0              0                 0   \n",
       "\n",
       "      Country_France  Country_Germany  Country_India  Country_Italy  \\\n",
       "0                  0                0              0              0   \n",
       "1                  0                0              0              0   \n",
       "2                  1                0              0              0   \n",
       "3                  0                0              0              0   \n",
       "4                  0                0              0              0   \n",
       "...              ...              ...            ...            ...   \n",
       "8758               0                0              0              0   \n",
       "8759               0                0              0              0   \n",
       "8760               0                0              0              0   \n",
       "8761               0                0              0              0   \n",
       "8762               0                0              0              0   \n",
       "\n",
       "      Country_Japan  Country_New Zealand  Country_Nigeria  \\\n",
       "0                 0                    0                0   \n",
       "1                 0                    0                0   \n",
       "2                 0                    0                0   \n",
       "3                 0                    0                0   \n",
       "4                 0                    0                0   \n",
       "...             ...                  ...              ...   \n",
       "8758              0                    0                0   \n",
       "8759              0                    0                0   \n",
       "8760              0                    0                0   \n",
       "8761              0                    0                0   \n",
       "8762              0                    0                0   \n",
       "\n",
       "      Country_South Africa  Country_South Korea  Country_Spain  \\\n",
       "0                        0                    0              0   \n",
       "1                        0                    0              0   \n",
       "2                        0                    0              0   \n",
       "3                        0                    0              0   \n",
       "4                        0                    0              0   \n",
       "...                    ...                  ...            ...   \n",
       "8758                     0                    0              0   \n",
       "8759                     0                    0              0   \n",
       "8760                     0                    0              0   \n",
       "8761                     0                    0              0   \n",
       "8762                     0                    0              0   \n",
       "\n",
       "      Country_Thailand  Country_United Kingdom  Country_United States  \\\n",
       "0                    0                       0                      0   \n",
       "1                    0                       0                      0   \n",
       "2                    0                       0                      0   \n",
       "3                    0                       0                      0   \n",
       "4                    1                       0                      0   \n",
       "...                ...                     ...                    ...   \n",
       "8758                 1                       0                      0   \n",
       "8759                 0                       0                      0   \n",
       "8760                 0                       0                      0   \n",
       "8761                 0                       0                      0   \n",
       "8762                 0                       1                      0   \n",
       "\n",
       "      Country_Vietnam  Systolic  Diastolic  BP_Interaction  \n",
       "0                   0       158         88           13904  \n",
       "1                   0       165         93           15345  \n",
       "2                   0       174         99           17226  \n",
       "3                   0       163        100           16300  \n",
       "4                   0        91         88            8008  \n",
       "...               ...       ...        ...             ...  \n",
       "8758                0        94         76            7144  \n",
       "8759                0       157        102           16014  \n",
       "8760                0       161         75           12075  \n",
       "8761                0       119         67            7973  \n",
       "8762                0       138         67            9246  \n",
       "\n",
       "[8763 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "clean the dataset\n",
    "'''\n",
    "\n",
    "# Switch income to log income.\n",
    "Income = df['Income']\n",
    "df['Log Income'] = np.log(Income)\n",
    "\n",
    "# Set Categorical Variables\n",
    "categorical_variables = ['Sex', 'Diet', 'Country']\n",
    "\n",
    "for col in categorical_variables:\n",
    "        df[col] = df[col].astype('category')\n",
    "        \n",
    "### One hot encode the categorical variables\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Diet','Country'])\n",
    "# Drop to prevent multicolinearity with binary variables\n",
    "df = df.drop(['Sex_Male', 'Diet_Average', 'Country_Argentina'], axis=1)\n",
    "\n",
    "### Seperate systolic and diastolic blood pressure into their own variables and create an interaction term.\n",
    "# Split the 'Blood Pressure' column into 'Systolic' and 'Diastolic'\n",
    "df[['Systolic', 'Diastolic']] = df['Blood Pressure'].str.split('/', expand=True).astype(int)\n",
    "\n",
    "# Drop for no need\n",
    "df = df.drop(['Patient ID', 'Blood Pressure', 'Income', 'Continent', 'Hemisphere'], axis=1)\n",
    "\n",
    "# Create interaction term by multiplying Systolic and Diastolic pressures\n",
    "df['BP_Interaction'] = df['Systolic'] * df['Diastolic']\n",
    "\n",
    "print(list(df.columns))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f985098-485c-4153-8c2a-8d340a2aae81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predict Heart Attack Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74df319-3bef-4c90-9b9e-83f87a58050d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Split Data to x and y train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67f022c2-2440-4317-b212-1411bed8deb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type of current x and y variables: <class 'pandas.core.frame.DataFrame'>\n",
      "Shape of X_train: (7010, 43)\n",
      "Shape of X_test: (1753, 43)\n",
      "Shape of y_train: (7010,)\n",
      "Shape of y_test: (1753,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate the target variable (y) and the features (X)\n",
    "X = df.drop('Heart Attack Risk', axis=1)\n",
    "y = df['Heart Attack Risk']\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "\n",
    "print(\"Object type of current x and y variables:\", type(X_train))\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f9b76c-5941-4dd3-a98f-dc50f56491bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2adcb6-92cc-450c-90df-f88d6b4f154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: torch.Size([7010, 43]) torch.Size([7010])\n",
      "Validation dataset shape: torch.Size([1753, 43]) torch.Size([1753])\n",
      "Training dataset type: <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Validation dataset type: <class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd  \n",
    "\n",
    "# Convert from numpy arrays or pandas DataFrames to PyTorch Tensors\n",
    "X_train = torch.tensor(X_train.values.astype(np.float32)) if isinstance(X_train, pd.DataFrame) else torch.tensor(X_train.astype(np.float32))\n",
    "y_train = torch.tensor(y_train.values.astype(np.int64)) if isinstance(y_train, pd.Series) else torch.tensor(y_train.astype(np.int64))\n",
    "X_test = torch.tensor(X_test.values.astype(np.float32)) if isinstance(X_test, pd.DataFrame) else torch.tensor(X_test.astype(np.float32))\n",
    "y_test = torch.tensor(y_test.values.astype(np.int64)) if isinstance(y_test, pd.Series) else torch.tensor(y_test.astype(np.int64))\n",
    "\n",
    "# Define datasets and DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "print(\"Training dataset shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation dataset shape:\", X_test.shape, y_test.shape)\n",
    "print(\"Training dataset type:\", type(X_train), type(y_train))\n",
    "print(\"Validation dataset type:\", type(X_test), type(y_test))\n",
    "\n",
    "def calculate_accuracy(model, data_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, targets in data_loader:\n",
    "            outputs = model(data)\n",
    "            predicted_classes = torch.sigmoid(outputs).round()\n",
    "            predictions.extend(predicted_classes.numpy().flatten())\n",
    "            actuals.extend(targets.numpy())\n",
    "\n",
    "    accuracy = accuracy_score(actuals, predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc39a50-5787-4068-81d9-38202230ff89",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b99f6973-14fb-4d60-b7dd-f258bcbecaab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6354820308043354, 'best_lambda': 100.0, 'best_l1_ratio': 0.09999999999999999}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def elastic_net_search(X_train, y_train, X_test, y_test, threshold=0.5):\n",
    "    # Setup ElasticNetCV with more iterations\n",
    "    model = ElasticNetCV(cv=5, l1_ratio=np.linspace(0.01, 1, 100), alphas=np.logspace(-6, 2, 100),\n",
    "                         max_iter=5000, tol=0.0001, random_state=42)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Binarize predictions based on a threshold\n",
    "    y_pred_binarized = (y_pred > threshold).astype(int)\n",
    "    \n",
    "    # Calculating Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_binarized)\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'best_lambda': model.alpha_,\n",
    "        'best_l1_ratio': model.l1_ratio_\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "results = elastic_net_search(X_train, y_train, X_test, y_test)\n",
    "print(results)\n",
    "\n",
    "# Plotting coefficients of the best model\n",
    "best_model = ElasticNetCV(cv=5, l1_ratio=results['best_l1_ratio'], alphas=[results['best_lambda']],\n",
    "                          max_iter=5000, tol=0.01, random_state=42)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "coefficients = best_model.coef_\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(coefficients, marker='o', linestyle='none')\n",
    "plt.title('Coefficients of the Best Model')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.xticks(ticks=np.arange(len(coefficients)), rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8245f396-df64-4528-a056-899ca78d2677",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SVM w RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b41e72e-a970-44f6-8e08-fb10ca9c8ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM with RBF kernel: 0.6354820308043354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM with RBF kernel\n",
    "svm_model = SVC(kernel='rbf', gamma='scale')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of SVM with RBF kernel: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90918507-c4e8-482a-b7c0-93d41c7ab169",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa34c25d-98e8-43e8-8cb2-4b670abe11cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 15476.574545565518\n",
      "Epoch 1, Loss: 15476.574545565518, Val Accuracy: 63.55%\n",
      "Epoch 2, Loss: 15555.275781666149, Val Accuracy: 36.45%\n",
      "Epoch 3, Loss: 16410.4976340554, Val Accuracy: 63.55%\n",
      "Epoch 4, Loss: 16208.423073785956, Val Accuracy: 63.55%\n",
      "Epoch 5, Loss: 15581.428387451171, Val Accuracy: 63.55%\n",
      "Epoch 6, Loss: 15346.040219809793, Val Accuracy: 36.45%\n",
      "Epoch 7, Loss: 14893.137850015813, Val Accuracy: 63.55%\n",
      "Epoch 8, Loss: 15209.295749282837, Val Accuracy: 36.45%\n",
      "Epoch 9, Loss: 15300.02749411843, Val Accuracy: 36.45%\n",
      "Epoch 10, Loss: 15642.634644664418, Val Accuracy: 63.55%\n"
     ]
    }
   ],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)  # Output is a single value\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Model setup\n",
    "model = LinearRegressionModel(input_dim=43)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target.view(-1, 1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "    # Calculate Accuracy on validation set after each epoch\n",
    "    val_accuracy = calculate_accuracy(model, val_loader)\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}, Val Accuracy: {val_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa9f54-fa25-452c-b10d-ff75d237e8ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "404c61c8-ac85-45b9-98f5-2f207e11a739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 32.007482101158665, Val Accuracy: 52.37%\n",
      "Epoch 2, Loss: 1.2882427497343583, Val Accuracy: 63.43%\n",
      "Epoch 3, Loss: 0.8545423670248552, Val Accuracy: 63.43%\n",
      "Epoch 4, Loss: 0.7618756976994601, Val Accuracy: 63.43%\n",
      "Epoch 5, Loss: 0.73295074430379, Val Accuracy: 63.43%\n",
      "Epoch 6, Loss: 0.7067302958531814, Val Accuracy: 63.43%\n",
      "Epoch 7, Loss: 0.6829167664051056, Val Accuracy: 63.43%\n",
      "Epoch 8, Loss: 0.6951531486077742, Val Accuracy: 63.43%\n",
      "Epoch 9, Loss: 0.6675323004072363, Val Accuracy: 63.43%\n",
      "Epoch 10, Loss: 0.6683717781847174, Val Accuracy: 63.43%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "def calculate_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "input_dim = 43  # Number of input features\n",
    "num_classes = 2  # Number of output classes\n",
    "\n",
    "nn_model = SimpleNN(input_dim, num_classes)\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    nn_model.train()\n",
    "    total_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = nn_model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculate Accuracy on validation set after each epoch\n",
    "    val_accuracy = calculate_accuracy(nn_model, val_loader)\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}, Val Accuracy: {val_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b282cb6-5163-4cc7-b5f0-d38d5c747068",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transformer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5457c630-c9f8-40b0-9692-a3feade92962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raywz\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Validation Accuracy: 63.43%\n",
      "Epoch [2/10], Validation Accuracy: 63.43%\n",
      "Epoch [3/10], Validation Accuracy: 63.43%\n",
      "Epoch [4/10], Validation Accuracy: 63.43%\n",
      "Epoch [5/10], Validation Accuracy: 63.43%\n",
      "Epoch [6/10], Validation Accuracy: 63.43%\n",
      "Epoch [7/10], Validation Accuracy: 63.43%\n",
      "Epoch [8/10], Validation Accuracy: 63.43%\n",
      "Epoch [9/10], Validation Accuracy: 63.43%\n",
      "Epoch [10/10], Validation Accuracy: 63.43%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# Define the transformer model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, num_classes):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        encoder_layers = TransformerEncoderLayer(input_dim, num_heads, hidden_dim)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define hyperparameters\n",
    "input_dim = 43\n",
    "hidden_dim = 128\n",
    "num_layers = 1\n",
    "num_heads = 1\n",
    "num_classes = 1\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create an instance of the transformer model\n",
    "model = TransformerModel(input_dim, hidden_dim, num_layers, num_heads, num_classes).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.unsqueeze(1)  # Add an extra dimension for sequence length\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.squeeze(), target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.unsqueeze(1)  # Add an extra dimension for sequence length\n",
    "            output = model(data)\n",
    "            predicted = torch.round(torch.sigmoid(output)).squeeze()\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5df1f2-29d0-415f-94ee-5d4cc18de16e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Predict Previous Heart Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303668d-e65e-40d0-89bb-76fcada8adc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split Data to x and y train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de3de7b7-8c03-48c1-8f9d-3ede70d6ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type of current x and y variables: <class 'numpy.ndarray'>\n",
      "Shape of X_train: (7010, 43)\n",
      "Shape of X_test: (1753, 43)\n",
      "Shape of y_train: (7010,)\n",
      "Shape of y_test: (1753,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Family History</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Alcohol Consumption</th>\n",
       "      <th>Exercise Hours Per Week</th>\n",
       "      <th>Previous Heart Problems</th>\n",
       "      <th>Medication Use</th>\n",
       "      <th>Stress Level</th>\n",
       "      <th>Sedentary Hours Per Day</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Triglycerides</th>\n",
       "      <th>Physical Activity Days Per Week</th>\n",
       "      <th>Sleep Hours Per Day</th>\n",
       "      <th>Heart Attack Risk</th>\n",
       "      <th>Log Income</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Diet_Healthy</th>\n",
       "      <th>Diet_Unhealthy</th>\n",
       "      <th>Country_Australia</th>\n",
       "      <th>Country_Brazil</th>\n",
       "      <th>Country_Canada</th>\n",
       "      <th>Country_China</th>\n",
       "      <th>Country_Colombia</th>\n",
       "      <th>Country_France</th>\n",
       "      <th>Country_Germany</th>\n",
       "      <th>Country_India</th>\n",
       "      <th>Country_Italy</th>\n",
       "      <th>Country_Japan</th>\n",
       "      <th>Country_New Zealand</th>\n",
       "      <th>Country_Nigeria</th>\n",
       "      <th>Country_South Africa</th>\n",
       "      <th>Country_South Korea</th>\n",
       "      <th>Country_Spain</th>\n",
       "      <th>Country_Thailand</th>\n",
       "      <th>Country_United Kingdom</th>\n",
       "      <th>Country_United States</th>\n",
       "      <th>Country_Vietnam</th>\n",
       "      <th>Systolic</th>\n",
       "      <th>Diastolic</th>\n",
       "      <th>BP_Interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>208</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.168189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.615001</td>\n",
       "      <td>31.251233</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12.473822</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>88</td>\n",
       "      <td>13904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>389</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.813242</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.963459</td>\n",
       "      <td>27.194973</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12.562936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>93</td>\n",
       "      <td>15345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>324</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.078353</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9.463426</td>\n",
       "      <td>28.176571</td>\n",
       "      <td>587</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12.368540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>99</td>\n",
       "      <td>17226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>383</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.828130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7.648981</td>\n",
       "      <td>36.464704</td>\n",
       "      <td>378</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11.741176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>100</td>\n",
       "      <td>16300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>318</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.804299</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.514821</td>\n",
       "      <td>21.809144</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11.986392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>8008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>60</td>\n",
       "      <td>121</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.917342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10.806373</td>\n",
       "      <td>19.655895</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12.369126</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>76</td>\n",
       "      <td>7144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>28</td>\n",
       "      <td>120</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.558426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.833038</td>\n",
       "      <td>23.993866</td>\n",
       "      <td>617</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>12.291704</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>102</td>\n",
       "      <td>16014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>47</td>\n",
       "      <td>250</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.148438</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.375214</td>\n",
       "      <td>35.406146</td>\n",
       "      <td>527</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10.518619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>75</td>\n",
       "      <td>12075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>36</td>\n",
       "      <td>178</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.789950</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.029104</td>\n",
       "      <td>27.294020</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12.254591</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>67</td>\n",
       "      <td>7973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>25</td>\n",
       "      <td>356</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.081748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9.005234</td>\n",
       "      <td>32.914151</td>\n",
       "      <td>180</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12.418511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>67</td>\n",
       "      <td>9246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8763 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Cholesterol  Heart Rate  Diabetes  Family History  Smoking  \\\n",
       "0      67          208          72         0               0        1   \n",
       "1      21          389          98         1               1        1   \n",
       "2      21          324          72         1               0        0   \n",
       "3      84          383          73         1               1        1   \n",
       "4      66          318          93         1               1        1   \n",
       "...   ...          ...         ...       ...             ...      ...   \n",
       "8758   60          121          61         1               1        1   \n",
       "8759   28          120          73         1               0        0   \n",
       "8760   47          250         105         0               1        1   \n",
       "8761   36          178          60         1               0        1   \n",
       "8762   25          356          75         1               1        0   \n",
       "\n",
       "      Obesity  Alcohol Consumption  Exercise Hours Per Week  \\\n",
       "0           0                    0                 4.168189   \n",
       "1           1                    1                 1.813242   \n",
       "2           0                    0                 2.078353   \n",
       "3           0                    1                 9.828130   \n",
       "4           1                    0                 5.804299   \n",
       "...       ...                  ...                      ...   \n",
       "8758        0                    1                 7.917342   \n",
       "8759        1                    0                16.558426   \n",
       "8760        1                    1                 3.148438   \n",
       "8761        0                    0                 3.789950   \n",
       "8762        0                    1                18.081748   \n",
       "\n",
       "      Previous Heart Problems  Medication Use  Stress Level  \\\n",
       "0                           0               0             9   \n",
       "1                           1               0             1   \n",
       "2                           1               1             9   \n",
       "3                           1               0             9   \n",
       "4                           1               0             6   \n",
       "...                       ...             ...           ...   \n",
       "8758                        1               1             8   \n",
       "8759                        0               0             8   \n",
       "8760                        1               0             5   \n",
       "8761                        1               1             5   \n",
       "8762                        0               0             8   \n",
       "\n",
       "      Sedentary Hours Per Day        BMI  Triglycerides  \\\n",
       "0                    6.615001  31.251233            286   \n",
       "1                    4.963459  27.194973            235   \n",
       "2                    9.463426  28.176571            587   \n",
       "3                    7.648981  36.464704            378   \n",
       "4                    1.514821  21.809144            231   \n",
       "...                       ...        ...            ...   \n",
       "8758                10.806373  19.655895             67   \n",
       "8759                 3.833038  23.993866            617   \n",
       "8760                 2.375214  35.406146            527   \n",
       "8761                 0.029104  27.294020            114   \n",
       "8762                 9.005234  32.914151            180   \n",
       "\n",
       "      Physical Activity Days Per Week  Sleep Hours Per Day  Heart Attack Risk  \\\n",
       "0                                   0                    6                  0   \n",
       "1                                   1                    7                  0   \n",
       "2                                   4                    4                  0   \n",
       "3                                   3                    4                  0   \n",
       "4                                   1                    5                  0   \n",
       "...                               ...                  ...                ...   \n",
       "8758                                7                    7                  0   \n",
       "8759                                4                    9                  0   \n",
       "8760                                4                    4                  1   \n",
       "8761                                2                    8                  0   \n",
       "8762                                7                    4                  1   \n",
       "\n",
       "      Log Income  Sex_Female  Diet_Healthy  Diet_Unhealthy  Country_Australia  \\\n",
       "0      12.473822           0             0               0                  0   \n",
       "1      12.562936           0             0               1                  0   \n",
       "2      12.368540           1             1               0                  0   \n",
       "3      11.741176           0             0               0                  0   \n",
       "4      11.986392           0             0               1                  0   \n",
       "...          ...         ...           ...             ...                ...   \n",
       "8758   12.369126           0             1               0                  0   \n",
       "8759   12.291704           1             1               0                  0   \n",
       "8760   10.518619           0             0               0                  0   \n",
       "8761   12.254591           0             0               1                  0   \n",
       "8762   12.418511           1             1               0                  0   \n",
       "\n",
       "      Country_Brazil  Country_Canada  Country_China  Country_Colombia  \\\n",
       "0                  0               0              0                 0   \n",
       "1                  0               1              0                 0   \n",
       "2                  0               0              0                 0   \n",
       "3                  0               1              0                 0   \n",
       "4                  0               0              0                 0   \n",
       "...              ...             ...            ...               ...   \n",
       "8758               0               0              0                 0   \n",
       "8759               0               1              0                 0   \n",
       "8760               1               0              0                 0   \n",
       "8761               1               0              0                 0   \n",
       "8762               0               0              0                 0   \n",
       "\n",
       "      Country_France  Country_Germany  Country_India  Country_Italy  \\\n",
       "0                  0                0              0              0   \n",
       "1                  0                0              0              0   \n",
       "2                  1                0              0              0   \n",
       "3                  0                0              0              0   \n",
       "4                  0                0              0              0   \n",
       "...              ...              ...            ...            ...   \n",
       "8758               0                0              0              0   \n",
       "8759               0                0              0              0   \n",
       "8760               0                0              0              0   \n",
       "8761               0                0              0              0   \n",
       "8762               0                0              0              0   \n",
       "\n",
       "      Country_Japan  Country_New Zealand  Country_Nigeria  \\\n",
       "0                 0                    0                0   \n",
       "1                 0                    0                0   \n",
       "2                 0                    0                0   \n",
       "3                 0                    0                0   \n",
       "4                 0                    0                0   \n",
       "...             ...                  ...              ...   \n",
       "8758              0                    0                0   \n",
       "8759              0                    0                0   \n",
       "8760              0                    0                0   \n",
       "8761              0                    0                0   \n",
       "8762              0                    0                0   \n",
       "\n",
       "      Country_South Africa  Country_South Korea  Country_Spain  \\\n",
       "0                        0                    0              0   \n",
       "1                        0                    0              0   \n",
       "2                        0                    0              0   \n",
       "3                        0                    0              0   \n",
       "4                        0                    0              0   \n",
       "...                    ...                  ...            ...   \n",
       "8758                     0                    0              0   \n",
       "8759                     0                    0              0   \n",
       "8760                     0                    0              0   \n",
       "8761                     0                    0              0   \n",
       "8762                     0                    0              0   \n",
       "\n",
       "      Country_Thailand  Country_United Kingdom  Country_United States  \\\n",
       "0                    0                       0                      0   \n",
       "1                    0                       0                      0   \n",
       "2                    0                       0                      0   \n",
       "3                    0                       0                      0   \n",
       "4                    1                       0                      0   \n",
       "...                ...                     ...                    ...   \n",
       "8758                 1                       0                      0   \n",
       "8759                 0                       0                      0   \n",
       "8760                 0                       0                      0   \n",
       "8761                 0                       0                      0   \n",
       "8762                 0                       1                      0   \n",
       "\n",
       "      Country_Vietnam  Systolic  Diastolic  BP_Interaction  \n",
       "0                   0       158         88           13904  \n",
       "1                   0       165         93           15345  \n",
       "2                   0       174         99           17226  \n",
       "3                   0       163        100           16300  \n",
       "4                   0        91         88            8008  \n",
       "...               ...       ...        ...             ...  \n",
       "8758                0        94         76            7144  \n",
       "8759                0       157        102           16014  \n",
       "8760                0       161         75           12075  \n",
       "8761                0       119         67            7973  \n",
       "8762                0       138         67            9246  \n",
       "\n",
       "[8763 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate the target variable (y) and the features (X)\n",
    "X = df.drop('Previous Heart Problems', axis=1)\n",
    "y = df['Previous Heart Problems']\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "\n",
    "print(\"Object type of current x and y variables:\", type(X_train))\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ea4b5-beed-4dcd-912c-1720100e076f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c6bd3e-7d95-454a-8e38-5ad00d57cb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: torch.Size([7010, 43]) torch.Size([7010])\n",
      "Validation dataset shape: torch.Size([1753, 43]) torch.Size([1753])\n",
      "Training dataset type: <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Validation dataset type: <class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd  \n",
    "\n",
    "# Convert from numpy arrays or pandas DataFrames to PyTorch Tensors\n",
    "X_train = torch.tensor(X_train.values.astype(np.float32)) if isinstance(X_train, pd.DataFrame) else torch.tensor(X_train.astype(np.float32))\n",
    "y_train = torch.tensor(y_train.values.astype(np.int64)) if isinstance(y_train, pd.Series) else torch.tensor(y_train.astype(np.int64))\n",
    "X_test = torch.tensor(X_test.values.astype(np.float32)) if isinstance(X_test, pd.DataFrame) else torch.tensor(X_test.astype(np.float32))\n",
    "y_test = torch.tensor(y_test.values.astype(np.int64)) if isinstance(y_test, pd.Series) else torch.tensor(y_test.astype(np.int64))\n",
    "\n",
    "# Define datasets and DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "print(\"Training dataset shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation dataset shape:\", X_test.shape, y_test.shape)\n",
    "print(\"Training dataset type:\", type(X_train), type(y_train))\n",
    "print(\"Validation dataset type:\", type(X_test), type(y_test))\n",
    "\n",
    "def calculate_accuracy(model, data_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, targets in data_loader:\n",
    "            outputs = model(data)\n",
    "            predicted_classes = torch.sigmoid(outputs).round()\n",
    "            predictions.extend(predicted_classes.numpy().flatten())\n",
    "            actuals.extend(targets.numpy())\n",
    "\n",
    "    accuracy = accuracy_score(actuals, predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8839cf00-4897-4794-91e1-5df2c5b4855b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e6a2754-dcf2-4c0b-b4c6-ec112e82ff7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5128351397604107, 'best_lambda': 100.0, 'best_l1_ratio': 0.01}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def elastic_net_search(X_train, y_train, X_test, y_test, threshold=0.5):\n",
    "    # Setup ElasticNetCV with more iterations\n",
    "    model = ElasticNetCV(cv=5, l1_ratio=np.linspace(0.01, 1, 100), alphas=np.logspace(-6, 2, 100),\n",
    "                         max_iter=5000, tol=0.0001, random_state=42)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Binarize predictions based on a threshold\n",
    "    y_pred_binarized = (y_pred > threshold).astype(int)\n",
    "    \n",
    "    # Calculating Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_binarized)\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'best_lambda': model.alpha_,\n",
    "        'best_l1_ratio': model.l1_ratio_\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "results = elastic_net_search(X_train, y_train, X_test, y_test)\n",
    "print(results)\n",
    "\n",
    "# Plotting coefficients of the best model\n",
    "best_model = ElasticNetCV(cv=5, l1_ratio=results['best_l1_ratio'], alphas=[results['best_lambda']],\n",
    "                          max_iter=5000, tol=0.01, random_state=42)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "coefficients = best_model.coef_\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(coefficients, marker='o', linestyle='none')\n",
    "plt.title('Coefficients of the Best Model')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.xticks(ticks=np.arange(len(coefficients)), rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e729f70-ad67-42f3-b2c8-c3dd11d3587b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SVM w RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4990b6c3-eba7-424a-9925-b887eb679441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM with RBF kernel: 0.4980034227039361\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM with RBF kernel\n",
    "svm_model = SVC(kernel='rbf', gamma='scale')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of SVM with RBF kernel: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e366b0b-1ae1-41db-8e15-c39a7a625d92",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc8651d-0e75-4893-a4d7-6fa3c50dc50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7508288096297872\n",
      "Epoch 1, Loss: 0.7508288096297872, Val Accuracy: 47.29%\n",
      "Epoch 2, Loss: 0.7481482738798315, Val Accuracy: 47.40%\n",
      "Epoch 3, Loss: 0.7446022375063462, Val Accuracy: 47.40%\n",
      "Epoch 4, Loss: 0.7414518448439511, Val Accuracy: 47.29%\n",
      "Epoch 5, Loss: 0.7388457444581118, Val Accuracy: 47.35%\n",
      "Epoch 6, Loss: 0.7357590886679563, Val Accuracy: 47.23%\n",
      "Epoch 7, Loss: 0.7330843914638866, Val Accuracy: 47.52%\n",
      "Epoch 8, Loss: 0.730310612375086, Val Accuracy: 47.52%\n",
      "Epoch 9, Loss: 0.728524185852571, Val Accuracy: 47.46%\n",
      "Epoch 10, Loss: 0.725964110547846, Val Accuracy: 47.46%\n"
     ]
    }
   ],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)  # Output is a single value\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Model setup\n",
    "model = LinearRegressionModel(input_dim=43)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target.view(-1, 1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "    # Calculate Accuracy on validation set after each epoch\n",
    "    val_accuracy = calculate_accuracy(model, val_loader)\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}, Val Accuracy: {val_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97166a2f-d601-4873-88ed-233a5df8f348",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d14fb41b-7da7-4c54-b499-9fb0d0a16cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6998896820978685, Val Accuracy: 48.89%\n",
      "Epoch 2, Loss: 0.6943886588920246, Val Accuracy: 50.20%\n",
      "Epoch 3, Loss: 0.6916777366941625, Val Accuracy: 49.86%\n",
      "Epoch 4, Loss: 0.692112800208005, Val Accuracy: 48.89%\n",
      "Epoch 5, Loss: 0.6898559234359047, Val Accuracy: 51.00%\n",
      "Epoch 6, Loss: 0.6907977093349803, Val Accuracy: 50.20%\n",
      "Epoch 7, Loss: 0.6898958319967443, Val Accuracy: 49.63%\n",
      "Epoch 8, Loss: 0.6876119597391649, Val Accuracy: 50.37%\n",
      "Epoch 9, Loss: 0.6866753090511669, Val Accuracy: 50.09%\n",
      "Epoch 10, Loss: 0.6872641509229487, Val Accuracy: 48.89%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "def calculate_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "input_dim = 43  # Number of input features\n",
    "num_classes = 2  # Number of output classes\n",
    "\n",
    "nn_model = SimpleNN(input_dim, num_classes)\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    nn_model.train()\n",
    "    total_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = nn_model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculate Accuracy on validation set after each epoch\n",
    "    val_accuracy = calculate_accuracy(nn_model, val_loader)\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}, Val Accuracy: {val_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d5261-12cd-46e2-a18d-46e5a1b2568f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transformer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "156d1ac9-7da7-4cf2-80ba-539fc5662b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raywz\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Validation Accuracy: 49.00%\n",
      "Epoch [2/10], Validation Accuracy: 48.94%\n",
      "Epoch [3/10], Validation Accuracy: 48.37%\n",
      "Epoch [4/10], Validation Accuracy: 49.23%\n",
      "Epoch [5/10], Validation Accuracy: 50.83%\n",
      "Epoch [6/10], Validation Accuracy: 50.88%\n",
      "Epoch [7/10], Validation Accuracy: 49.46%\n",
      "Epoch [8/10], Validation Accuracy: 50.94%\n",
      "Epoch [9/10], Validation Accuracy: 49.34%\n",
      "Epoch [10/10], Validation Accuracy: 50.54%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# Define the transformer model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, num_classes):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        encoder_layers = TransformerEncoderLayer(input_dim, num_heads, hidden_dim)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define hyperparameters\n",
    "input_dim = 43\n",
    "hidden_dim = 128\n",
    "num_layers = 1\n",
    "num_heads = 1\n",
    "num_classes = 1\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create an instance of the transformer model\n",
    "model = TransformerModel(input_dim, hidden_dim, num_layers, num_heads, num_classes).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.unsqueeze(1)  # Add an extra dimension for sequence length\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.squeeze(), target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.unsqueeze(1)  # Add an extra dimension for sequence length\n",
    "            output = model(data)\n",
    "            predicted = torch.round(torch.sigmoid(output)).squeeze()\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f513681-b41d-457d-b2c1-6400178d1181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5be45b5e-7b47-4aae-bf6a-5b0709b0f967",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Predict Stress Level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e67c0e5-b151-4ac1-90b3-d7376d00d012",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split Data to x and y train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ebaebd-58b3-4a5a-87b5-e5b942d43cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type of current x and y variables: <class 'numpy.ndarray'>\n",
      "Shape of X_train: (7010, 43)\n",
      "Shape of X_test: (1753, 43)\n",
      "Shape of y_train: (7010,)\n",
      "Shape of y_test: (1753,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Family History</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Alcohol Consumption</th>\n",
       "      <th>Exercise Hours Per Week</th>\n",
       "      <th>Previous Heart Problems</th>\n",
       "      <th>Medication Use</th>\n",
       "      <th>Stress Level</th>\n",
       "      <th>Sedentary Hours Per Day</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Triglycerides</th>\n",
       "      <th>Physical Activity Days Per Week</th>\n",
       "      <th>Sleep Hours Per Day</th>\n",
       "      <th>Heart Attack Risk</th>\n",
       "      <th>Log Income</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Diet_Healthy</th>\n",
       "      <th>Diet_Unhealthy</th>\n",
       "      <th>Country_Australia</th>\n",
       "      <th>Country_Brazil</th>\n",
       "      <th>Country_Canada</th>\n",
       "      <th>Country_China</th>\n",
       "      <th>Country_Colombia</th>\n",
       "      <th>Country_France</th>\n",
       "      <th>Country_Germany</th>\n",
       "      <th>Country_India</th>\n",
       "      <th>Country_Italy</th>\n",
       "      <th>Country_Japan</th>\n",
       "      <th>Country_New Zealand</th>\n",
       "      <th>Country_Nigeria</th>\n",
       "      <th>Country_South Africa</th>\n",
       "      <th>Country_South Korea</th>\n",
       "      <th>Country_Spain</th>\n",
       "      <th>Country_Thailand</th>\n",
       "      <th>Country_United Kingdom</th>\n",
       "      <th>Country_United States</th>\n",
       "      <th>Country_Vietnam</th>\n",
       "      <th>Systolic</th>\n",
       "      <th>Diastolic</th>\n",
       "      <th>BP_Interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>208</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.168189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.615001</td>\n",
       "      <td>31.251233</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12.473822</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>88</td>\n",
       "      <td>13904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>389</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.813242</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.963459</td>\n",
       "      <td>27.194973</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12.562936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>93</td>\n",
       "      <td>15345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>324</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.078353</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9.463426</td>\n",
       "      <td>28.176571</td>\n",
       "      <td>587</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12.368540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>99</td>\n",
       "      <td>17226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>383</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.828130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7.648981</td>\n",
       "      <td>36.464704</td>\n",
       "      <td>378</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11.741176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>100</td>\n",
       "      <td>16300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>318</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.804299</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.514821</td>\n",
       "      <td>21.809144</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11.986392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>8008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>60</td>\n",
       "      <td>121</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.917342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10.806373</td>\n",
       "      <td>19.655895</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12.369126</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>76</td>\n",
       "      <td>7144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>28</td>\n",
       "      <td>120</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.558426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.833038</td>\n",
       "      <td>23.993866</td>\n",
       "      <td>617</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>12.291704</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>102</td>\n",
       "      <td>16014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>47</td>\n",
       "      <td>250</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.148438</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.375214</td>\n",
       "      <td>35.406146</td>\n",
       "      <td>527</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10.518619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>75</td>\n",
       "      <td>12075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>36</td>\n",
       "      <td>178</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.789950</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.029104</td>\n",
       "      <td>27.294020</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12.254591</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>67</td>\n",
       "      <td>7973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>25</td>\n",
       "      <td>356</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.081748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9.005234</td>\n",
       "      <td>32.914151</td>\n",
       "      <td>180</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12.418511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>67</td>\n",
       "      <td>9246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8763 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Cholesterol  Heart Rate  Diabetes  Family History  Smoking  \\\n",
       "0      67          208          72         0               0        1   \n",
       "1      21          389          98         1               1        1   \n",
       "2      21          324          72         1               0        0   \n",
       "3      84          383          73         1               1        1   \n",
       "4      66          318          93         1               1        1   \n",
       "...   ...          ...         ...       ...             ...      ...   \n",
       "8758   60          121          61         1               1        1   \n",
       "8759   28          120          73         1               0        0   \n",
       "8760   47          250         105         0               1        1   \n",
       "8761   36          178          60         1               0        1   \n",
       "8762   25          356          75         1               1        0   \n",
       "\n",
       "      Obesity  Alcohol Consumption  Exercise Hours Per Week  \\\n",
       "0           0                    0                 4.168189   \n",
       "1           1                    1                 1.813242   \n",
       "2           0                    0                 2.078353   \n",
       "3           0                    1                 9.828130   \n",
       "4           1                    0                 5.804299   \n",
       "...       ...                  ...                      ...   \n",
       "8758        0                    1                 7.917342   \n",
       "8759        1                    0                16.558426   \n",
       "8760        1                    1                 3.148438   \n",
       "8761        0                    0                 3.789950   \n",
       "8762        0                    1                18.081748   \n",
       "\n",
       "      Previous Heart Problems  Medication Use  Stress Level  \\\n",
       "0                           0               0             9   \n",
       "1                           1               0             1   \n",
       "2                           1               1             9   \n",
       "3                           1               0             9   \n",
       "4                           1               0             6   \n",
       "...                       ...             ...           ...   \n",
       "8758                        1               1             8   \n",
       "8759                        0               0             8   \n",
       "8760                        1               0             5   \n",
       "8761                        1               1             5   \n",
       "8762                        0               0             8   \n",
       "\n",
       "      Sedentary Hours Per Day        BMI  Triglycerides  \\\n",
       "0                    6.615001  31.251233            286   \n",
       "1                    4.963459  27.194973            235   \n",
       "2                    9.463426  28.176571            587   \n",
       "3                    7.648981  36.464704            378   \n",
       "4                    1.514821  21.809144            231   \n",
       "...                       ...        ...            ...   \n",
       "8758                10.806373  19.655895             67   \n",
       "8759                 3.833038  23.993866            617   \n",
       "8760                 2.375214  35.406146            527   \n",
       "8761                 0.029104  27.294020            114   \n",
       "8762                 9.005234  32.914151            180   \n",
       "\n",
       "      Physical Activity Days Per Week  Sleep Hours Per Day  Heart Attack Risk  \\\n",
       "0                                   0                    6                  0   \n",
       "1                                   1                    7                  0   \n",
       "2                                   4                    4                  0   \n",
       "3                                   3                    4                  0   \n",
       "4                                   1                    5                  0   \n",
       "...                               ...                  ...                ...   \n",
       "8758                                7                    7                  0   \n",
       "8759                                4                    9                  0   \n",
       "8760                                4                    4                  1   \n",
       "8761                                2                    8                  0   \n",
       "8762                                7                    4                  1   \n",
       "\n",
       "      Log Income  Sex_Female  Diet_Healthy  Diet_Unhealthy  Country_Australia  \\\n",
       "0      12.473822           0             0               0                  0   \n",
       "1      12.562936           0             0               1                  0   \n",
       "2      12.368540           1             1               0                  0   \n",
       "3      11.741176           0             0               0                  0   \n",
       "4      11.986392           0             0               1                  0   \n",
       "...          ...         ...           ...             ...                ...   \n",
       "8758   12.369126           0             1               0                  0   \n",
       "8759   12.291704           1             1               0                  0   \n",
       "8760   10.518619           0             0               0                  0   \n",
       "8761   12.254591           0             0               1                  0   \n",
       "8762   12.418511           1             1               0                  0   \n",
       "\n",
       "      Country_Brazil  Country_Canada  Country_China  Country_Colombia  \\\n",
       "0                  0               0              0                 0   \n",
       "1                  0               1              0                 0   \n",
       "2                  0               0              0                 0   \n",
       "3                  0               1              0                 0   \n",
       "4                  0               0              0                 0   \n",
       "...              ...             ...            ...               ...   \n",
       "8758               0               0              0                 0   \n",
       "8759               0               1              0                 0   \n",
       "8760               1               0              0                 0   \n",
       "8761               1               0              0                 0   \n",
       "8762               0               0              0                 0   \n",
       "\n",
       "      Country_France  Country_Germany  Country_India  Country_Italy  \\\n",
       "0                  0                0              0              0   \n",
       "1                  0                0              0              0   \n",
       "2                  1                0              0              0   \n",
       "3                  0                0              0              0   \n",
       "4                  0                0              0              0   \n",
       "...              ...              ...            ...            ...   \n",
       "8758               0                0              0              0   \n",
       "8759               0                0              0              0   \n",
       "8760               0                0              0              0   \n",
       "8761               0                0              0              0   \n",
       "8762               0                0              0              0   \n",
       "\n",
       "      Country_Japan  Country_New Zealand  Country_Nigeria  \\\n",
       "0                 0                    0                0   \n",
       "1                 0                    0                0   \n",
       "2                 0                    0                0   \n",
       "3                 0                    0                0   \n",
       "4                 0                    0                0   \n",
       "...             ...                  ...              ...   \n",
       "8758              0                    0                0   \n",
       "8759              0                    0                0   \n",
       "8760              0                    0                0   \n",
       "8761              0                    0                0   \n",
       "8762              0                    0                0   \n",
       "\n",
       "      Country_South Africa  Country_South Korea  Country_Spain  \\\n",
       "0                        0                    0              0   \n",
       "1                        0                    0              0   \n",
       "2                        0                    0              0   \n",
       "3                        0                    0              0   \n",
       "4                        0                    0              0   \n",
       "...                    ...                  ...            ...   \n",
       "8758                     0                    0              0   \n",
       "8759                     0                    0              0   \n",
       "8760                     0                    0              0   \n",
       "8761                     0                    0              0   \n",
       "8762                     0                    0              0   \n",
       "\n",
       "      Country_Thailand  Country_United Kingdom  Country_United States  \\\n",
       "0                    0                       0                      0   \n",
       "1                    0                       0                      0   \n",
       "2                    0                       0                      0   \n",
       "3                    0                       0                      0   \n",
       "4                    1                       0                      0   \n",
       "...                ...                     ...                    ...   \n",
       "8758                 1                       0                      0   \n",
       "8759                 0                       0                      0   \n",
       "8760                 0                       0                      0   \n",
       "8761                 0                       0                      0   \n",
       "8762                 0                       1                      0   \n",
       "\n",
       "      Country_Vietnam  Systolic  Diastolic  BP_Interaction  \n",
       "0                   0       158         88           13904  \n",
       "1                   0       165         93           15345  \n",
       "2                   0       174         99           17226  \n",
       "3                   0       163        100           16300  \n",
       "4                   0        91         88            8008  \n",
       "...               ...       ...        ...             ...  \n",
       "8758                0        94         76            7144  \n",
       "8759                0       157        102           16014  \n",
       "8760                0       161         75           12075  \n",
       "8761                0       119         67            7973  \n",
       "8762                0       138         67            9246  \n",
       "\n",
       "[8763 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate the target variable (y) and the features (X)\n",
    "X = df.drop('Stress Level', axis=1)\n",
    "y = df['Stress Level']\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)\n",
    "\n",
    "print(\"Object type of current x and y variables:\", type(X_train))\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de5918f-bb3d-4fdc-b29e-069b9bc26dca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a665fd04-c957-4277-a5f9-a98ac3de5b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: torch.Size([7010, 43]) torch.Size([7010])\n",
      "Validation dataset shape: torch.Size([1753, 43]) torch.Size([1753])\n",
      "Training dataset type: <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Validation dataset type: <class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd  \n",
    "\n",
    "# Convert from numpy arrays or pandas DataFrames to PyTorch Tensors\n",
    "X_train = torch.tensor(X_train.values.astype(np.float32)) if isinstance(X_train, pd.DataFrame) else torch.tensor(X_train.astype(np.float32))\n",
    "y_train = torch.tensor(y_train.values.astype(np.int64)) if isinstance(y_train, pd.Series) else torch.tensor(y_train.astype(np.int64))\n",
    "X_test = torch.tensor(X_test.values.astype(np.float32)) if isinstance(X_test, pd.DataFrame) else torch.tensor(X_test.astype(np.float32))\n",
    "y_test = torch.tensor(y_test.values.astype(np.int64)) if isinstance(y_test, pd.Series) else torch.tensor(y_test.astype(np.int64))\n",
    "\n",
    "# Define datasets and DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "print(\"Training dataset shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation dataset shape:\", X_test.shape, y_test.shape)\n",
    "print(\"Training dataset type:\", type(X_train), type(y_train))\n",
    "print(\"Validation dataset type:\", type(X_test), type(y_test))\n",
    "\n",
    "def calculate_accuracy(model, data_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, targets in data_loader:\n",
    "            outputs = model(data)\n",
    "            predicted_classes = torch.sigmoid(outputs).round()\n",
    "            predictions.extend(predicted_classes.numpy().flatten())\n",
    "            actuals.extend(targets.numpy())\n",
    "\n",
    "    accuracy = accuracy_score(actuals, predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6023aec1-7e07-40d3-95de-5b5afdf03405",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec229eb3-25f9-4e50-8e2e-10d646155690",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.09583571021106674, 'best_lambda': 0.10235310218990269, 'best_l1_ratio': 0.8400000000000001}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAA9hAAAPYQGoP6dpAABe/ElEQVR4nO3de3zP9f//8fv7vaPTNofNyGxzKESRw4zKoWVCIeVQco7kmE50cAhJBxGlDx0cokQ6UJRDZ4cYiULOhA1pmxk23s/fH37e39628X7r/TLbbtfL5X3h/To83o/Xe+/3Xru/jjZjjBEAAAAAAPA6e243AAAAAABAfkXoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAORLS5cuVc2aNRUYGCibzabk5GRJ0uzZs1WlShX5+fkpJCREktS4cWM1btzY49ew2WwaOXKk13q+1qSlpalXr14KDw+XzWbT4MGDPa4xcuRI2Ww2HTt2zPsNwiNRUVHq1q3bFc2b3z/rAGAlQjcAwDK7du1Snz59VKFCBQUGBiooKEgNGzbUpEmTdOrUKcte9++//1b79u1VqFAhvfnmm5o9e7aKFCmibdu2qVu3bqpYsaKmT5+uadOmWdaDt8ydO1cTJ07Mldd+8cUXNWPGDPXt21ezZ8/WQw89dMlpP/vss6vX3EVmzJghm83m8ggLC1OTJk20ZMkSy143PT1dI0eO1HfffefW9N99952zvw8++CDbaRo2bCibzabq1at7sVMAQG7xze0GAAD505dffqn7779fAQEB6tKli6pXr66MjAz99NNPevLJJ/X7779bFnrXrVunEydOaPTo0YqLi3MO/+677+RwODRp0iRVqlTJOfybb765otc5deqUfH2tXZXOnTtXW7ZsuaK9zP/VypUrVb9+fY0YMeKy07744ou677771KZNG+sbu4QXXnhB0dHRMsYoKSlJM2bMUIsWLbRo0SK1atXK66+Xnp6uUaNGSZJHR0sEBgZq7ty56ty5s8vwvXv3atWqVQoMDPRmmwCAXEToBgB43Z49e9SxY0dFRkZq5cqVKlOmjHNcv379tHPnTn355ZeWvf6RI0ckyXn4+OWG+/v7X9Hr5PdgdOTIEVWrVi232/DIXXfdpTp16jif9+zZU6VLl9aHH35oSei+Ui1atNAXX3yhY8eOqVSpUs7hc+fOVenSpVW5cmX9888/udghAMBbOLwcAOB1L7/8stLS0vTuu++6BO4LKlWqpEGDBjmfnz17VqNHj1bFihUVEBCgqKgoPfPMMzpz5kyWeZcsWaLbbrtNRYoUUbFixdSyZUv9/vvvzvGNGzdW165dJUl169aVzWZTt27dFBUV5dxjGxoa6nKOanbndJ8+fVojR47U9ddfr8DAQJUpU0b33nuvdu3a5Zwmu/NcDx48qB49eqh06dIKCAjQjTfeqPfee89lmguHGH/88ccaO3asypUrp8DAQN1xxx3auXOny7J8+eWX2rdvn/OQ5KioKOf4yZMn68Ybb1ThwoVVvHhx1alTR3Pnzs3mJ+LqyJEjzjAaGBiom2++WTNnzszS3549e/Tll186X3vv3r3Z1rPZbDp58qRmzpzpnPbic4eTk5PVrVs3hYSEKDg4WN27d1d6enqWWh988IFq166tQoUKqUSJEurYsaMOHDhw2WXKSUhIiAoVKpTliASHw6GJEyfqxhtvVGBgoEqXLq0+ffpkCbrr169XfHy8SpUqpUKFCik6Olo9evSQdH6vdGhoqCRp1KhRzmV359zn1q1bKyAgQPPnz3cZPnfuXLVv314+Pj5Z5nH3e2KM0ZgxY1SuXDkVLlxYTZo0cfmO/FtycrIGDx6siIgIBQQEqFKlSho/frwcDsdllwEA4B72dAMAvG7RokWqUKGCGjRo4Nb0vXr10syZM3Xffffp8ccf19q1azVu3Dht3bpVn376qXO62bNnq2vXroqPj9f48eOVnp6uqVOn6tZbb9XGjRsVFRWlZ599VjfccIOmTZvmPNS4YsWKatOmjWbNmqVPP/1UU6dOVdGiRXXTTTdl28+5c+fUqlUrrVixQh07dtSgQYN04sQJLVu2TFu2bFHFihWznS8pKUn169eXzWZT//79FRoaqiVLlqhnz55KTU3Ncoj4Sy+9JLvdrieeeEIpKSl6+eWX9eCDD2rt2rWSpGeffVYpKSn666+/9Prrr0uSihYtKkmaPn26Bg4cqPvuu0+DBg3S6dOn9dtvv2nt2rV64IEHcnyvT506pcaNG2vnzp3q37+/oqOjNX/+fHXr1k3JyckaNGiQqlatqtmzZ+uxxx5TuXLl9Pjjj0uSM2BebPbs2erVq5fq1aun3r17S1KW96h9+/aKjo7WuHHjtGHDBr3zzjsKCwvT+PHjndOMHTtWzz//vNq3b69evXrp6NGjmjx5sm6//XZt3LgxyxEK2UlJSdGxY8dkjNGRI0c0efJkpaWlZTmMu0+fPpoxY4a6d++ugQMHas+ePZoyZYo2btyon3/+WX5+fjpy5IiaNWum0NBQDR06VCEhIdq7d68WLlzofD+mTp2qvn37qm3btrr33nslKcfP1b8VLlxYrVu31ocffqi+fftKkjZt2qTff/9d77zzjn777bcs87j7PRk+fLjGjBmjFi1aqEWLFtqwYYOaNWumjIwMl3rp6elq1KiRDh48qD59+qh8+fJatWqVhg0bpsOHD+fatQQAIN8xAAB4UUpKipFkWrdu7db0v/76q5FkevXq5TL8iSeeMJLMypUrjTHGnDhxwoSEhJiHH37YZbrExEQTHBzsMvz99983ksy6detcph0xYoSRZI4ePeoyvFGjRqZRo0bO5++9956RZCZMmJClX4fD4fy/JDNixAjn8549e5oyZcqYY8eOuczTsWNHExwcbNLT040xxnz77bdGkqlatao5c+aMc7pJkyYZSWbz5s3OYS1btjSRkZFZ+mjdurW58cYbswy/nIkTJxpJ5oMPPnAOy8jIMLGxsaZo0aImNTXVOTwyMtK0bNnSrbpFihQxXbt2zTL8wnveo0cPl+Ft27Y1JUuWdD7fu3ev8fHxMWPHjnWZbvPmzcbX1zfL8Itd+Jlf/AgICDAzZsxwmfbHH380ksycOXNchi9dutRl+Keffprt5+jfjh49muVzcCkXfvbz5883ixcvNjabzezfv98YY8yTTz5pKlSoYIw5/5n898/X3e/JkSNHjL+/v2nZsqXLZ/WZZ54xklx+RqNHjzZFihQxf/75p0vNoUOHGh8fH2dfxmT9rAMA3Mfh5QAAr0pNTZUkFStWzK3pv/rqK0nSkCFDXIZf2Lt64dzvZcuWKTk5WZ06ddKxY8ecDx8fH8XExOjbb7/11iLok08+UalSpTRgwIAs42w2W7bzGGP0ySef6O6775YxxqXH+Ph4paSkaMOGDS7zdO/e3eV88ttuu02StHv37sv2GBISor/++kvr1q3zZNH01VdfKTw8XJ06dXIO8/Pz08CBA5WWlqbvv//eo3rueuSRR1ye33bbbfr777+dn5eFCxfK4XCoffv2Lu9deHi4Kleu7PbP980339SyZcu0bNkyffDBB2rSpIl69erl3DstSfPnz1dwcLDuvPNOl9eqXbu2ihYt6nytC3vWFy9erMzMTC+8C66aNWumEiVK6KOPPpIxRh999JHLz+Xf3P2eLF++XBkZGRowYIDLZzW7C/HNnz9ft912m4oXL+7yPsTFxencuXP64YcfvLGYAFDgcXg5AMCrgoKCJEknTpxwa/p9+/bJbre7XE1cksLDwxUSEqJ9+/ZJknbs2CFJatq06SVf1xt27dqlG264waMrkx89elTJycmaNm1ajldlv3AhtwvKly/v8rx48eKS5NYFtJ5++mktX75c9erVU6VKldSsWTM98MADatiw4SXn27dvnypXriy73XW7e9WqVZ3jrXCpZQ0KCtKOHTtkjFHlypWznd/Pz8+t16lXr57LhdQ6deqkWrVqqX///mrVqpX8/f21Y8cOpaSkKCwsLNsaF35OjRo1Urt27TRq1Ci9/vrraty4sdq0aaMHHnhAAQEBbvVzKX5+frr//vs1d+5c1atXTwcOHMjx1AB3vycX/r34fQwNDXW+5xfs2LFDv/32W46nDVz8eQUAXBlCNwDAq4KCglS2bFlt2bLFo/ly2oN8wYULO82ePVvh4eFZxlt9667LudBf586dnRdyu9jF5/pmd7Es6fxe88upWrWqtm/frsWLF2vp0qX65JNP9NZbb2n48OHOW1hdSy63rA6HQzabTUuWLMl22gvnsnvKbrerSZMmmjRpknbs2KEbb7xRDodDYWFhmjNnTrbzXAihNptNCxYs0Jo1a7Ro0SJ9/fXX6tGjh1577TWtWbPminv6twceeEBvv/22Ro4cqZtvvvmyV4u/3PfEEw6HQ3feeaeeeuqpbMdff/31XnstACjICN0AAK9r1aqVpk2bptWrVys2NvaS00ZGRsrhcGjHjh3Ova3S+YuSJScnKzIyUtL/XZgrLCzM5d7bVqhYsaLWrl2rzMxMt/ewhoaGqlixYjp37pxX+7tUyCpSpIg6dOigDh06KCMjQ/fee6/Gjh2rYcOG5Xg7s8jISP32229yOBwue7u3bdvmHO/tPt1RsWJFGWMUHR3t9bB39uxZSVJaWprztZYvX66GDRuqUKFCl52/fv36ql+/vsaOHau5c+fqwQcf1EcffaRevXr95+W+9dZbVb58eX333XcuF5W7mLvfkwv/7tixQxUqVHBOd/To0SxHUFSsWFFpaWmWf58AoKDjnG4AgNc99dRTKlKkiHr16qWkpKQs43ft2qVJkyZJOn+/YklZrpQ8YcIESVLLli0lSfHx8QoKCtKLL76Y7fm1R48e9Vr/7dq107FjxzRlypQs43LaC+3j46N27drpk08+yXYv/5X2V6RIEaWkpGQZ/vfff7s89/f3V7Vq1WSMueT5xy1atFBiYqLmzZvnHHb27FlNnjxZRYsWVaNGja64z+Tk5CuaV5Luvfde+fj4aNSoUVneY2NMluV1V2Zmpr755hv5+/s7w2r79u117tw5jR49Osv0Z8+edS7HP//8k6WXmjVrSpLzNl2FCxeWpCtedpvNpjfeeEMjRozQQw89lON07n5P4uLi5Ofnp8mTJ7v0nt2VyNu3b6/Vq1fr66+/zjIuOTnZubECAPDfsKcbAOB1FStW1Ny5c9WhQwdVrVpVXbp0UfXq1ZWRkaFVq1Y5b1ElSTfffLO6du2qadOmKTk5WY0aNdIvv/yimTNnqk2bNmrSpImk84etT506VQ899JBuueUWdezYUaGhodq/f7++/PJLNWzYMNuQfCW6dOmiWbNmaciQIfrll19022236eTJk1q+fLkeffRRtW7dOtv5XnrpJX377beKiYnRww8/rGrVqun48ePasGGDli9fruPHj3vcS+3atTVv3jwNGTJEdevWVdGiRXX33XerWbNmCg8PV8OGDVW6dGlt3bpVU6ZMUcuWLS95EbvevXvrf//7n7p166aEhARFRUVpwYIF+vnnnzVx4kS3L4CXXZ/Lly/XhAkTVLZsWUVHRysmJsbt+StWrKgxY8Zo2LBh2rt3r9q0aaNixYppz549+vTTT9W7d2898cQTl62zZMkS5177I0eOaO7cudqxY4eGDh3qPO+/UaNG6tOnj8aNG6dff/1VzZo1k5+fn3bs2KH58+dr0qRJuu+++zRz5ky99dZbatu2rSpWrKgTJ05o+vTpCgoKcobgQoUKqVq1apo3b56uv/56lShRQtWrV1f16tXdXvbWrVvn+Jm6wN3vSWhoqJ544gmNGzdOrVq1UosWLbRx40YtWbJEpUqVcqn55JNP6osvvlCrVq3UrVs31a5dWydPntTmzZu1YMEC7d27N8s8AIArkCvXTAcAFAh//vmnefjhh01UVJTx9/c3xYoVMw0bNjSTJ082p0+fdk6XmZlpRo0aZaKjo42fn5+JiIgww4YNc5nmgm+//dbEx8eb4OBgExgYaCpWrGi6detm1q9f75zmv94yzBhj0tPTzbPPPuvsKTw83Nx3331m165dzmmUzW2UkpKSTL9+/UxERIRzvjvuuMNMmzbNZRn0/28b9W979uwxksz777/vHJaWlmYeeOABExISYiQ5bx/2v//9z9x+++2mZMmSJiAgwFSsWNE8+eSTJiUlJesP4iJJSUmme/fuplSpUsbf39/UqFHD5TUv8OSWYdu2bTO33367KVSokMutqXJ6zy/8jPbs2eMy/JNPPjG33nqrKVKkiClSpIipUqWK6devn9m+ffslXz+7W4YFBgaamjVrmqlTp7rcPuuCadOmmdq1a5tChQqZYsWKmRo1apinnnrKHDp0yBhjzIYNG0ynTp1M+fLlTUBAgAkLCzOtWrVy+awZY8yqVatM7dq1jb+//2VvrZXTz/5iF98yzBj3vyfnzp0zo0aNMmXKlDGFChUyjRs3Nlu2bDGRkZFZbut24sQJM2zYMFOpUiXj7+9vSpUqZRo0aGBeffVVk5GR4ZzucssFAMiZzRg3rtYCAAAAAAA8xjndAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARXxzu4H8wOFw6NChQypWrJhsNltutwMAAAAAsJgxRidOnFDZsmVlt+e8P5vQ7QWHDh1SREREbrcBAAAAALjKDhw4oHLlyuU4ntDtBcWKFZN0/s0OCgrK5W4AAAAAAFZLTU1VRESEMw/mhNDtBRcOKQ8KCiJ0AwAAAEABcrlTjLmQGgAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABbJc6H7zTffVFRUlAIDAxUTE6NffvnlktPPnz9fVapUUWBgoGrUqKGvvvoqx2kfeeQR2Ww2TZw40ctdAwAAAAAKojwVuufNm6chQ4ZoxIgR2rBhg26++WbFx8fryJEj2U6/atUqderUST179tTGjRvVpk0btWnTRlu2bMky7aeffqo1a9aobNmyVi8GAAAAAKCAyFOhe8KECXr44YfVvXt3VatWTW+//bYKFy6s9957L9vpJ02apObNm+vJJ59U1apVNXr0aN1yyy2aMmWKy3QHDx7UgAEDNGfOHPn5+V2NRQEAAAAAFAB5JnRnZGQoISFBcXFxzmF2u11xcXFavXp1tvOsXr3aZXpJio+Pd5ne4XDooYce0pNPPqkbb7zRmuYBAAAAAAWSb2434K5jx47p3LlzKl26tMvw0qVLa9u2bdnOk5iYmO30iYmJzufjx4+Xr6+vBg4c6HYvZ86c0ZkzZ5zPU1NT3Z4XAAAAAFBw5Jk93VZISEjQpEmTNGPGDNlsNrfnGzdunIKDg52PiIgIC7sEAAAAAORVeSZ0lypVSj4+PkpKSnIZnpSUpPDw8GznCQ8Pv+T0P/74o44cOaLy5cvL19dXvr6+2rdvnx5//HFFRUXl2MuwYcOUkpLifBw4cOC/LRwAAAAAIF/KM6Hb399ftWvX1ooVK5zDHA6HVqxYodjY2GzniY2NdZlekpYtW+ac/qGHHtJvv/2mX3/91fkoW7asnnzySX399dc59hIQEKCgoCCXBwAAAAAAF8sz53RL0pAhQ9S1a1fVqVNH9erV08SJE3Xy5El1795dktSlSxddd911GjdunCRp0KBBatSokV577TW1bNlSH330kdavX69p06ZJkkqWLKmSJUu6vIafn5/Cw8N1ww03XN2FAwAAAADkO3kqdHfo0EFHjx7V8OHDlZiYqJo1a2rp0qXOi6Xt379fdvv/7bxv0KCB5s6dq+eee07PPPOMKleurM8++0zVq1fPrUUAAAAAABQgNmOMye0m8rrU1FQFBwcrJSWFQ80BAAAAoABwNwfmmXO6AQAAAADIawjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYJM+F7jfffFNRUVEKDAxUTEyMfvnll0tOP3/+fFWpUkWBgYGqUaOGvvrqK+e4zMxMPf3006pRo4aKFCmismXLqkuXLjp06JDViwEAAAAAKADyVOieN2+ehgwZohEjRmjDhg26+eabFR8fryNHjmQ7/apVq9SpUyf17NlTGzduVJs2bdSmTRtt2bJFkpSenq4NGzbo+eef14YNG7Rw4UJt375d99xzz9VcLAAAAABAPmUzxpjcbsJdMTExqlu3rqZMmSJJcjgcioiI0IABAzR06NAs03fo0EEnT57U4sWLncPq16+vmjVr6u233872NdatW6d69epp3759Kl++vFt9paamKjg4WCkpKQoKCrqCJQMAAAAA5CXu5sA8s6c7IyNDCQkJiouLcw6z2+2Ki4vT6tWrs51n9erVLtNLUnx8fI7TS1JKSopsNptCQkK80jcAAAAAoODyze0G3HXs2DGdO3dOpUuXdhleunRpbdu2Ldt5EhMTs50+MTEx2+lPnz6tp59+Wp06dbrkloozZ87ozJkzzuepqanuLgYAAAAAoADJM3u6rZaZman27dvLGKOpU6dectpx48YpODjY+YiIiLhKXQIAAAAA8pI8E7pLlSolHx8fJSUluQxPSkpSeHh4tvOEh4e7Nf2FwL1v3z4tW7bssudlDxs2TCkpKc7HgQMHrmCJAAAAAAD5XZ4J3f7+/qpdu7ZWrFjhHOZwOLRixQrFxsZmO09sbKzL9JK0bNkyl+kvBO4dO3Zo+fLlKlmy5GV7CQgIUFBQkMsDAAAAAICL5ZlzuiVpyJAh6tq1q+rUqaN69epp4sSJOnnypLp37y5J6tKli6677jqNGzdOkjRo0CA1atRIr732mlq2bKmPPvpI69ev17Rp0ySdD9z33XefNmzYoMWLF+vcuXPO871LlCghf3//3FlQAAAAAEC+kKdCd4cOHXT06FENHz5ciYmJqlmzppYuXeq8WNr+/ftlt//fzvsGDRpo7ty5eu655/TMM8+ocuXK+uyzz1S9enVJ0sGDB/XFF19IkmrWrOnyWt9++60aN258VZYLAAAAAJA/5an7dF+ruE83AAAAABQs+e4+3QAAAAAA5DWEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIlcUunft2qXnnntOnTp10pEjRyRJS5Ys0e+//+7V5gAAAAAAyMs8Dt3ff/+9atSoobVr12rhwoVKS0uTJG3atEkjRozweoMAAAAAAORVHofuoUOHasyYMVq2bJn8/f2dw5s2bao1a9Z4tTkAAAAAAPIyj0P35s2b1bZt2yzDw8LCdOzYMa80BQAAAABAfuBx6A4JCdHhw4ezDN+4caOuu+46rzQFAAAAAEB+4HHo7tixo55++mklJibKZrPJ4XDo559/1hNPPKEuXbpY0SMAAAAAAHmSx6H7xRdfVJUqVRQREaG0tDRVq1ZNt99+uxo0aKDnnnvOih4BAAAAAMiTbMYYcyUz7t+/X1u2bFFaWppq1aqlypUre7u3PCM1NVXBwcFKSUlRUFBQbrcDAAAAALCYuznQ90pfoHz58ipfvvyVzg4AAAAAQL7nceju0aPHJce/9957V9wMAAAAAAD5iceh+59//nF5npmZqS1btig5OVlNmzb1WmMAAAAAAOR1HofuTz/9NMswh8Ohvn37qmLFil5pCgAAAACA/MDjq5dnW8Ru15AhQ/T66697oxwAAAAAAPmCV0K3JO3atUtnz571VjkAAAAAAPI8jw8vHzJkiMtzY4wOHz6sL7/8Ul27dvVaYwAAAAAA5HUeh+6NGze6PLfb7QoNDdVrr7122SubAwAAAABQkHgcur/99lsr+gAAAAAAIN/x2jndAAAAAADAlVt7umvVqiWbzeZWwQ0bNvynhgAAAAAAyC/cCt1t2rSxuA0AAAAAAPIfmzHG5HYTeV1qaqqCg4OVkpKioKCg3G4HAAAAAGAxd3Mg53QDAAAAAGARj69efu7cOb3++uv6+OOPtX//fmVkZLiMP378uNeaAwAAAAAgL/N4T/eoUaM0YcIEdejQQSkpKRoyZIjuvfde2e12jRw50oIWAQAAAADImzwO3XPmzNH06dP1+OOPy9fXV506ddI777yj4cOHa82aNVb0CAAAAABAnuRx6E5MTFSNGjUkSUWLFlVKSookqVWrVvryyy+92x0AAAAAAHmYx6G7XLlyOnz4sCSpYsWK+uabbyRJ69atU0BAgHe7AwAAAAAgD/M4dLdt21YrVqyQJA0YMEDPP/+8KleurC5duqhHjx5ebxAAAAAAgLzK7ft0T5kyRZ07d1ZISIjL8NWrV2v16tWqXLmy7r77bit6vOZxn24AAAAAKFjczYFuh+7g4GBlZmaqbdu26tmzp5o2beq1ZvM6QjcAAAAAFCzu5kC3Dy9PTEzU22+/rUOHDunOO+9UdHS0Ro8erQMHDnilYQAAAAAA8hu3Q3ehQoXUpUsXffvtt9qxY4ceeughvfvuu4qOjlbz5s01f/58ZWZmWtkrAAAAAAB5ituHl2fHGKPly5drxowZ+uyzz1SkSBEdOXLEm/3lCRxeDgAAAAAFi9cPL8+OzWaTr6+vbDabjDHs6QYAAAAA4F+uKHQfOHBAL7zwgipUqKA777xThw4d0vTp05337wYAAAAAAJKvuxNmZGRo4cKFeu+997Ry5UqVKVNGXbt2VY8ePVShQgUrewQAAAAAIE9yO3SHh4crPT1drVq10qJFixQfHy+7/T8dnQ4AAAAAQL7mduh+7rnn9NBDDyk0NNTKfgAAAAAAyDfcDt1Dhgyxsg8AAAAAAPIdjg8HAAAAAMAihG4AAAAAACxC6AYAAAAAwCIeh+4XXnhB6enpWYafOnVKL7zwgleaAgAAAAAgP7AZY4wnM/j4+Ojw4cMKCwtzGf73338rLCxM586d82qDeUFqaqqCg4OVkpKioKCg3G4HAAAAAGAxd3Ogx3u6jTGy2WxZhm/atEklSpTwtBwAAAAAAPmW27cMK168uGw2m2w2m66//nqX4H3u3DmlpaXpkUcesaRJAAAAAADyIrdD98SJE2WMUY8ePTRq1CgFBwc7x/n7+ysqKkqxsbGWNAkAAAAAQF7kduju2rWrJCk6OloNGjSQn5+fZU0BAAAAAJAfuB26L2jUqJEcDof+/PNPHTlyRA6Hw2X87bff7rXmAAAAAADIyzwO3WvWrNEDDzygffv26eILn9tstgJ59XIAAAAAALLjceh+5JFHVKdOHX355ZcqU6ZMtlcyBwAAAAAAVxC6d+zYoQULFqhSpUpW9AMAAAAAQL7h8X26Y2JitHPnTit6AQAAAAAgX/F4T/eAAQP0+OOPKzExUTVq1MhyFfObbrrJa81l580339Qrr7yixMRE3XzzzZo8ebLq1auX4/Tz58/X888/r71796py5coaP368WrRo4RxvjNGIESM0ffp0JScnq2HDhpo6daoqV65s6XJcLeccRr/sOa4jJ04rrFig6kWXkI/9yk8J8GY9esv93grKctIbveXVWvRGb3m1Fr3RW16tRW/5s7fcZjMXXw3tMuz2rDvHbTabjDGWX0ht3rx56tKli95++23FxMRo4sSJmj9/vrZv366wsLAs069atUq33367xo0bp1atWmnu3LkaP368NmzYoOrVq0uSxo8fr3HjxmnmzJmKjo7W888/r82bN+uPP/5QYGCgW32lpqYqODhYKSkpCgoK8uoy/xdLtxzWqEV/6HDKaeewMsGBGnF3NTWvXiZX69Fb7vdWUJaT3ugtr9aiN3rLq7Xojd7yai16y5+9WcndHOhx6N63b98lx0dGRnpSziMxMTGqW7eupkyZIklyOByKiIjQgAEDNHTo0CzTd+jQQSdPntTixYudw+rXr6+aNWvq7bffljFGZcuW1eOPP64nnnhCkpSSkqLSpUtrxowZ6tixo1t9XYuhe+mWw+r7wQZd/MO9sH1oaudbPPrQerMeveV+bwVlOemN3vJqLXqjt7xai97oLa/Worf82ZvV3M2BHp/THRkZecmHVTIyMpSQkKC4uDjnMLvdrri4OK1evTrbeVavXu0yvSTFx8c7p9+zZ48SExNdpgkODlZMTEyONfOCcw6jUYv+yPJhleQcNmrRHzrncG97izfr0Vvu91ZQlpPe6C2v1qI3esurteiN3vJqLXrLn71dSzwO3ZI0e/ZsNWzYUGXLlnXu+Z44caI+//xzrzb3b8eOHdO5c+dUunRpl+GlS5dWYmJitvMkJiZecvoL/3pSU5LOnDmj1NRUl8e15Jc9x10Ox7iYkXQ45bR+2XP8qtejt9zvraAsJ73RW16tRW/0lldr0Ru95dVa9JY/e7uWeBy6p06dqiFDhqhFixZKTk52nsMdEhKiiRMneru/a9K4ceMUHBzsfEREROR2Sy6OnMj5w5rb09HblU13rdby9nT0dmXT0duVTXet1vL2dPR2ZdMVlN4KynJ6ezp6u7LprtVa3p6O3q5sOm+/5rXE49A9efJkTZ8+Xc8++6x8fHycw+vUqaPNmzd7tbl/K1WqlHx8fJSUlOQyPCkpSeHh4dnOEx4efsnpL/zrSU1JGjZsmFJSUpyPAwcOeLw8VgorFnjNTkdvVzbdtVrL29PR25VNR29XNt21Wsvb09HblU1XUHorKMvp7eno7cqmu1ZreXs6eruy6bz9mtcSj0P3nj17VKtWrSzDAwICdPLkSa80lR1/f3/Vrl1bK1ascA5zOBxasWKFYmNjs50nNjbWZXpJWrZsmXP66OhohYeHu0yTmpqqtWvX5lhTOr+sQUFBLo9rSb3oEioTHOi84MDFbDp/BcB60SWuej16y/3eCspy0hu95dVa9EZvebUWvdFbXq1Fb/mzt2uJx6E7Ojpav/76a5bhS5cuVdWqVb3RU46GDBmi6dOna+bMmdq6dav69u2rkydPqnv37pKkLl26aNiwYc7pBw0apKVLl+q1117Ttm3bNHLkSK1fv179+/eXdP5WZ4MHD9aYMWP0xRdfaPPmzerSpYvKli2rNm3aWLosVvKx2zTi7mqSlOVDe+H5iLuruX2vO2/Wo7fc762gLCe90VterUVv9JZXa9EbveXVWvSWP3u7lngcuocMGaJ+/fpp3rx5Msbol19+0dixYzVs2DA99dRTVvTo1KFDB7366qsaPny4atasqV9//VVLly51Xght//79Onz4sHP6Bg0aaO7cuZo2bZpuvvlmLViwQJ999pnzHt2S9NRTT2nAgAHq3bu36tatq7S0NC1dutTte3Rfq5pXL6OpnW9ReLDrcoQHB17Rpfa9WY/ecr+3grKc9EZvebUWvdFbXq1Fb/SWV2vRW/7s7Vrh8X26JWnOnDkaOXKkdu3aJUkqW7asRo0apZ49e3q9wbzgWrxP9wXnHEa/7DmuIydOK6zY+cMx/svWIW/Wo7fc762gLCe90VterUVv9JZXa9EbveXVWvSWP3uzirs58IpC9wXp6elKS0tTWFjYlZbIF67l0A0AAAAA8D53c6Dvf3mRwoULq3Dhwv+lBAAAAAAA+ZZbofuWW27RihUrVLx4cdWqVUs2W8679jds2OC15gAAAAAAyMvcCt2tW7dWQECAJOXpq3oDAAAAAHA1/adzunEe53QDAAAAQMHibg70+JZh69at09q1a7MMX7t2rdavX+9pOQAAAAAA8i2PQ3e/fv104MCBLMMPHjyofv36eaUpAAAAAADyA49D9x9//KFbbrkly/BatWrpjz/+8EpTAAAAAADkBx6H7oCAACUlJWUZfvjwYfn6/qc7kAEAAAAAkK94HLqbNWumYcOGKSUlxTksOTlZzzzzjO68806vNgcAAAAAQF7m8a7pV199VbfffrsiIyNVq1YtSdKvv/6q0qVLa/bs2V5vEAAAAACAvMrj0H3dddfpt99+05w5c7Rp0yYVKlRI3bt3V6dOneTn52dFjwAAAAAA5ElXdBJ2kSJF1Lt3b2/3AgAAAABAvuJW6P7iiy901113yc/PT1988cUlp73nnnu80hgAAAAAAHmdzRhjLjeR3W5XYmKiwsLCZLfnfO01m82mc+fOebXBvCA1NVXBwcFKSUlRUFBQbrcDAAAAALCYuznQrT3dDocj2/8DAAAAAICcuXXLsBIlSujYsWOSpB49eujEiROWNgUAAAAAQH7gVujOyMhQamqqJGnmzJk6ffq0pU0BAAAAAJAfuHV4eWxsrNq0aaPatWvLGKOBAweqUKFC2U773nvvebVBAAAAAADyKrdC9wcffKDXX39du3btkiSlpKSwtxsAAAAAgMtw6+rl/xYdHa3169erZMmSVvWU53D1cgAAAAAoWNzNgR5fSK1Jkyby9/f3TpcAAAAAAORjXEgNAAAAAACLcCE1AAAAAAAs4vGF1Gw2GxdSAwAAAADADVxIzQu4kBoAAAAAFCzu5kC39nT/2549e5z/P336tAIDA6+sQwAAAAAA8jm3LqT2bw6HQ6NHj9Z1112nokWLavfu3ZKk559/Xu+++67XGwQAAAAAIK/yOHSPGTNGM2bM0Msvv+xy67Dq1avrnXfe8WpzAAAAAADkZR6H7lmzZmnatGl68MEH5ePj4xx+8803a9u2bV5tDgAAAACAvMzj0H3w4EFVqlQpy3CHw6HMzEyvNAUAAAAAQH7gceiuVq2afvzxxyzDFyxYoFq1anmlKQAAAAAA8gOPr14+fPhwde3aVQcPHpTD4dDChQu1fft2zZo1S4sXL7aiRwAAAAAA8iSP93S3bt1aixYt0vLly1WkSBENHz5cW7du1aJFi3TnnXda0SMAAAAAAHmSzRhjcruJvM7dm6IDAAAAAPIHd3Ogx4eXX5CQkKCtW7dKkm688UbO5wYAAAAA4CIeh+4jR46oY8eO+u677xQSEiJJSk5OVpMmTfTRRx8pNDTU2z0CAAAAAJAneXxO94ABA3TixAn9/vvvOn78uI4fP64tW7YoNTVVAwcOtKJHAAAAAADyJI/P6Q4ODtby5ctVt25dl+G//PKLmjVrpuTkZG/2lydwTjcAAAAAFCzu5kCP93Q7HA75+fllGe7n5yeHw+FpOQAAAAAA8i2PQ3fTpk01aNAgHTp0yDns4MGDeuyxx3THHXd4tTkAAAAAAPIyj0P3lClTlJqaqqioKFWsWFEVK1ZUdHS0UlNTNXnyZCt6BAAAAAAgT/L46uURERHasGGDli9frm3btkmSqlatqri4OK83BwAAAABAXubxhdSQFRdSAwAAAICCxesXUlu5cqWqVaum1NTULONSUlJ044036scff7yybgEAAAAAyIfcDt0TJ07Uww8/nG2CDw4OVp8+fTRhwgSvNgcAAAAAQF7mdujetGmTmjdvnuP4Zs2aKSEhwStNAQAAAACQH7gdupOSkrK9P/cFvr6+Onr0qFeaAgAAAAAgP3A7dF933XXasmVLjuN/++03lSlTxitNAQAAAACQH7gdulu0aKHnn39ep0+fzjLu1KlTGjFihFq1auXV5gAAAAAAyMvcvmVYUlKSbrnlFvn4+Kh///664YYbJEnbtm3Tm2++qXPnzmnDhg0qXbq0pQ1fi7hlGAAAAAAULO7mQF93C5YuXVqrVq1S3759NWzYMF3I6jabTfHx8XrzzTcLZOAGAAAAACAnboduSYqMjNRXX32lf/75Rzt37pQxRpUrV1bx4sWt6g8AAAAAgDzLo9B9QfHixVW3bl1v9wIAAAAAQL7i9oXUAAAAAACAZwjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYJM+E7uPHj+vBBx9UUFCQQkJC1LNnT6WlpV1yntOnT6tfv34qWbKkihYtqnbt2ikpKck5ftOmTerUqZMiIiJUqFAhVa1aVZMmTbJ6UQAAAAAABUSeCd0PPvigfv/9dy1btkyLFy/WDz/8oN69e19ynscee0yLFi3S/Pnz9f333+vQoUO69957neMTEhIUFhamDz74QL///rueffZZDRs2TFOmTLF6cQAAAAAABYDNGGNyu4nL2bp1q6pVq6Z169apTp06kqSlS5eqRYsW+uuvv1S2bNks86SkpCg0NFRz587VfffdJ0natm2bqlatqtWrV6t+/frZvla/fv20detWrVy50u3+UlNTFRwcrJSUFAUFBV3BEgIAAAAA8hJ3c2Ce2NO9evVqhYSEOAO3JMXFxclut2vt2rXZzpOQkKDMzEzFxcU5h1WpUkXly5fX6tWrc3ytlJQUlShR4pL9nDlzRqmpqS4PAAAAAAAulidCd2JiosLCwlyG+fr6qkSJEkpMTMxxHn9/f4WEhLgML126dI7zrFq1SvPmzbvsYevjxo1TcHCw8xEREeH+wgAAAAAACoxcDd1Dhw6VzWa75GPbtm1XpZctW7aodevWGjFihJo1a3bJaYcNG6aUlBTn48CBA1elRwAAAABA3uKbmy/++OOPq1u3bpecpkKFCgoPD9eRI0dchp89e1bHjx9XeHh4tvOFh4crIyNDycnJLnu7k5KSsszzxx9/6I477lDv3r313HPPXbbvgIAABQQEXHY6AAAAAEDBlquhOzQ0VKGhoZedLjY2VsnJyUpISFDt2rUlSStXrpTD4VBMTEy289SuXVt+fn5asWKF2rVrJ0navn279u/fr9jYWOd0v//+u5o2baquXbtq7NixXlgqAAAAAADOyxNXL5eku+66S0lJSXr77beVmZmp7t27q06dOpo7d64k6eDBg7rjjjs0a9Ys1atXT5LUt29fffXVV5oxY4aCgoI0YMAASefP3ZbOH1LetGlTxcfH65VXXnG+lo+Pj1sbAy7g6uUAAAAAULC4mwNzdU+3J+bMmaP+/fvrjjvukN1uV7t27fTGG284x2dmZmr79u1KT093Dnv99ded0545c0bx8fF66623nOMXLFigo0eP6oMPPtAHH3zgHB4ZGam9e/deleUCAAAAAORfeWZP97WMPd0AAAAAULDkq/t0AwAAAACQFxG6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwSJ4J3cePH9eDDz6ooKAghYSEqGfPnkpLS7vkPKdPn1a/fv1UsmRJFS1aVO3atVNSUlK20/79998qV66cbDabkpOTLVgCAAAAAEBBk2dC94MPPqjff/9dy5Yt0+LFi/XDDz+od+/el5znscce06JFizR//nx9//33OnTokO69995sp+3Zs6duuukmK1oHAAAAABRQNmOMye0mLmfr1q2qVq2a1q1bpzp16kiSli5dqhYtWuivv/5S2bJls8yTkpKi0NBQzZ07V/fdd58kadu2bapatapWr16t+vXrO6edOnWq5s2bp+HDh+uOO+7QP//8o5CQELf7S01NVXBwsFJSUhQUFPTfFhYAAAAAcM1zNwfmiT3dq1evVkhIiDNwS1JcXJzsdrvWrl2b7TwJCQnKzMxUXFycc1iVKlVUvnx5rV692jnsjz/+0AsvvKBZs2bJbnfv7Thz5oxSU1NdHgAAAAAAXCxPhO7ExESFhYW5DPP19VWJEiWUmJiY4zz+/v5Z9liXLl3aOc+ZM2fUqVMnvfLKKypfvrzb/YwbN07BwcHOR0REhGcLBAAAAAAoEHI1dA8dOlQ2m+2Sj23btln2+sOGDVPVqlXVuXNnj+dLSUlxPg4cOGBRhwAAAACAvMw3N1/88ccfV7du3S45TYUKFRQeHq4jR464DD979qyOHz+u8PDwbOcLDw9XRkaGkpOTXfZ2JyUlOedZuXKlNm/erAULFkiSLpzeXqpUKT377LMaNWpUtrUDAgIUEBDgziICAAAAAAqwXA3doaGhCg0Nvex0sbGxSk5OVkJCgmrXri3pfGB2OByKiYnJdp7atWvLz89PK1asULt27SRJ27dv1/79+xUbGytJ+uSTT3Tq1CnnPOvWrVOPHj30448/qmLFiv918QAAAAAABVyuhm53Va1aVc2bN9fDDz+st99+W5mZmerfv786duzovHL5wYMHdccdd2jWrFmqV6+egoOD1bNnTw0ZMkQlSpRQUFCQBgwYoNjYWOeVyy8O1seOHXO+nidXLwcAAAAAIDt5InRL0pw5c9S/f3/dcccdstvtateund544w3n+MzMTG3fvl3p6enOYa+//rpz2jNnzig+Pl5vvfVWbrQPAAAAACiA8sR9uq913KcbAAAAAAqWfHWfbgAAAAAA8iJCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGAR39xuID8wxkiSUlNTc7kTAAAAAMDVcCH/XciDOSF0e8GJEyckSREREbncCQAAAADgajpx4oSCg4NzHG8zl4vluCyHw6FDhw6pWLFistlsud1OFqmpqYqIiNCBAwcUFBR0TdWjt/xVi96ujXr0lr9q0du1Ua+g9FZQlpPero1612oters26nm7NysYY3TixAmVLVtWdnvOZ26zp9sL7Ha7ypUrl9ttXFZQUJBXP7DerEdv+auWt+vRW+7X8na9gtJbQVlOb9ejt/xVy9v16C33a3m73rVay9v16C33a1nhUnu4L+BCagAAAAAAWITQDQAAAACARQjdBUBAQIBGjBihgICAa64eveWvWt6uR2+5X8vb9QpKbwVlOb1dj97yVy1v16O33K/l7XrXai1v16O33K+V27iQGgAAAAAAFmFPNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDl8AlDwAAAAD8F7653QC879ixY3rvvfe0evVqJSYmSpLCw8PVoEEDdevWTaGhobncYd4REBCgTZs2qWrVqrndCgAAAIA8iKuX5zPr1q1TfHy8ChcurLi4OJUuXVqSlJSUpBUrVig9PV1ff/216tSpkyv9nTp1SgkJCSpRooSqVavmMu706dP6+OOP1aVLF7frbd26VWvWrFFsbKyqVKmibdu2adKkSTpz5ow6d+6spk2bulVnyJAh2Q6fNGmSOnfurJIlS0qSJkyY4HZv/3by5El9/PHH2rlzp8qUKaNOnTo5a15tAwYMUPv27XXbbbflyutfyuHDhzV16lT99NNPOnz4sOx2uypUqKA2bdqoW7du8vHxye0WgTzpl19+ybIhNjY2VvXq1fPq6/zzzz9atGiRR7/HHQ6H7PasB945HA799ddfKl++vNu1jDHau3evIiIi5Ovrq4yMDH366ac6c+aMWrRooVKlSrldKztNmzbV+++/r8jIyP9UR5L27NnjXCdUr17d7fnOnDkju90uPz8/SdKuXbv03nvvaf/+/YqMjFTPnj0VHR3tVq1PPvlEd911lwoXLnxFy5CdTZs2KSEhQY0bN1aFChX0+++/680335TD4VDbtm0VHx/vUb2VK1dmWSfcc889qly5std6Bgqaq7FOuJL1geTddcI1xSBfiYmJMb179zYOhyPLOIfDYXr37m3q16/vtdfbv3+/6d69u1vTbt++3URGRhqbzWbsdru5/fbbzaFDh5zjExMTjd1ud/u1lyxZYvz9/U2JEiVMYGCgWbJkiQkNDTVxcXGmadOmxsfHx6xYscKtWjabzdSsWdM0btzY5WGz2UzdunVN48aNTZMmTdzurWrVqubvv/82xpx/j6KiokxwcLCpW7euKVGihAkLCzO7d+92q1ZCQoLLtLNmzTINGjQw5cqVMw0bNjQffvih231dWFa73W4qV65sXnrpJXP48GGP5r/Y5MmTzUMPPeTsY9asWaZq1armhhtuMMOGDTOZmZlu1Vm3bp0JDg42tWvXNrfeeqvx8fExDz30kOnQoYMJCQkxDRo0MKmpqR71dubMGTNv3jwzePBg07FjR9OxY0czePBg8/HHH5szZ854vKyXkpiYaEaNGuXRPAcOHDAnTpzIMjwjI8N8//33HtU6duyYWblypfNzd/ToUfPSSy+ZUaNGmT/++MOjWtmJjo42f/7553+u43A4zMqVK820adPMokWLTEZGhtvzHjhwwBw9etT5/IcffjAPPPCAufXWW82DDz5oVq1a5VEvr776qtm7d69H81zKokWLzPPPP29++uknY4wxK1asMHfddZeJj483//vf/zyqlZ6ebt59913TvXt307x5c9OiRQvTv39/s3z5co/qJCUlmVtvvdXYbDYTGRlp6tWrZ+rVq+f8XXzrrbeapKQkj2peyq+//ur27/GUlBRz//33m8DAQBMWFmaef/55c/bsWed4T9cJ27ZtM5GRkcZut5tKlSqZ3bt3m9q1a5siRYqYwoULm1KlSrn9Gf7888+zffj4+JgpU6Y4n7urb9++zu96enq6adeunbHb7c7fx02aNMn2d0F2GjVqZObPn2+MMeann34yAQEB5qabbjIdOnQwtWrVMoULF3b7u2Cz2UxQUJB5+OGHzZo1a9xenpx88sknxsfHx5QsWdIULVrULFu2zISEhJi4uDgTHx9vfHx8zJw5c9yqlZSUZOrVq2fsdrvx9fU1drvd1K5d24SHhxsfHx/z5JNPXlGPa9euNRMnTjRDhw41Q4cONRMnTjRr1669olo5OX78uJk5c6bH8507dy7H4fv27XO7jsPhMLt373auf8+cOWM++ugjM3PmTJffof9FkyZNvPL7c/fu3eabb74xmzdv9nje06dPu6xDdu7caZ555hnTuXNn8+yzz7r9d5YxxixYsMCcPHnS4x5y8uuvv5p3333X7Nq1yxhjzJYtW0zfvn1Nnz59zNKlS6+o5ooVK8yoUaPMI488Yh599FHz6quverxevprrBE/WB8Z4f51wrSF05zOBgYFm69atOY7funWrCQwM9NrrefKFatOmjWnZsqU5evSo2bFjh2nZsqWJjo52rkg8/TLFxsaaZ5991hhjzIcffmiKFy9unnnmGef4oUOHmjvvvNOtWuPGjTPR0dFZQrqvr6/5/fff3e7pApvN5vyl9eCDD5oGDRqY5ORkY4wxJ06cMHFxcaZTp05u1brpppvMsmXLjDHGTJ8+3RQqVMgMHDjQTJ061QwePNgULVrUvPvuux71tnz5cjNo0CBTqlQp4+fnZ+655x6zaNGiHFf4ORk9erQpVqyYadeunQkPDzcvvfSSKVmypBkzZox58cUXTWhoqBk+fLhbtRo2bGhGjhzpfD579mwTExNjjDn/B0zNmjXNwIED3e5tx44dpkKFCiYwMNA0atTItG/f3rRv3940atTIBAYGmkqVKpkdO3Z4tLyX4sl34dChQ6Zu3brGbrc7Ny78+w9uT78La9euNcHBwcZms5nixYub9evXm+joaFO5cmVTsWJFU6hQIZOQkOBWrUmTJmX78PHxMcOGDXM+d9ddd93l/Oz//fffJiYmxthsNhMaGmrsdrupUqWKOXLkiFu16tWrZxYtWmSMMeazzz4zdrvd3HPPPebpp582bdu2NX5+fs7x7rDZbMbHx8fExcWZjz766D9tiHn77beNr6+vqV27tgkKCjKzZ882xYoVM7169TJ9+vQxhQoVMhMnTnSr1o4dO0xkZKQJCwszERERxmazmZYtW5qYmBjj4+Nj7r//frc3ZrVr187Exsaabdu2ZRm3bds206BBA3Pfffe5vZwpKSmXfPz4449uf3YHDhxorr/+ejN//nwzffp0ExkZaVq2bOn8OSQmJhqbzeZ2b61btzb33HOP+e2338zgwYNN1apVTevWrU1GRoY5ffq0ufvuu03nzp3dqnUhDNtsthwfnnxH7Xa7c50wbNgwU65cObNy5Upz8uRJ89NPP5mKFSuaoUOHulUrKCjI+Yd2o0aNzGOPPeYy/rnnnjMNGzZ0ezlfeOEFU6tWLWOz2cyNN95oXn/9dXPs2DG3l+3fbrnlFjNmzBhjzPn1ckhIiHnhhRec41999VVTs2ZNt2p16NDBtGnTxqSkpJjTp0+b/v37my5duhhjzoePkiVLuv2dMqbghA1vbnwyxrsboLy58cmYa3cDlDc3Phnj3Q1Q3lwneHN9YIz31wnXGkJ3PhMVFXXJraszZ840kZGRbtfL6Zfthcfrr7/u9hcqLCzM/Pbbb87nDofDPPLII6Z8+fJm165dHgeNoKAgZ2g6d+6c8fX1NRs2bHCO37x5syldurTb9X755Rdz/fXXm8cff9y55dQbobtChQrmm2++cRn/888/m4iICLdqFSpUyLk1uVatWmbatGku4+fMmWOqVat2Rb1lZGSYefPmOVcCZcuWNc8884zbYbRixYrmk08+Mcac/yPDx8fHfPDBB87xCxcuNJUqVXKrVqFChZxbhI05/zP18/MziYmJxhhjvvnmG1O2bFm3ahljTFxcnGndurVJSUnJMi4lJcW0bt3aNGvWzO16mzZtuuRj3rx5bn9+u3TpYmJiYsy6devMsmXLTO3atU2dOnXM8ePHjTGer1ji4uJMr169TGpqqnnllVdMuXLlTK9evZzju3fvbtq0aeNWLZvNZsqVK2eioqJcHjabzVx33XUmKirKREdHu93bvz9vffv2NdWqVXPufThw4ICpXbu2eeSRR9yqVaRIEee8MTEx5qWXXnIZP3nyZFOrVi2Penv//fdN69atjZ+fnylZsqQZNGjQFe1xqVatmvO7uXLlShMYGGjefPNN5/j333/fVK1a1a1ad911l+nTp4/ziKWXXnrJ3HXXXcYYY/78808TFRVlRowY4VatokWLuvxevNj69etN0aJF3aplzP+F0ZwenoTR8uXLm2+//db5/OjRo6ZevXqmWbNm5vTp0x6vE0JDQ83GjRuNMcakpaUZm81mfvzxR+f4n3/+2ZQvX96tWs2bNzctW7bMEsK8sU6oXr26mTt3rsv4zz//3Fx//fVu1SpSpIhz43rp0qXNr7/+6jJ+586dbv9M/93X+vXrTd++fU1ISIgJCAgw999/f5Z1lzu97dmzxxhzfh3v5+fnst7ftWuX270FBQWZLVu2OJ+npaUZPz8/5+/02bNnmxtuuMHt3gpK2PDmxidjvLsBypsbn4y5djdAeXPjkzHe3QDlzXWCN9cHxnh/nXCtIXTnM1OmTDEBAQFm4MCB5vPPPzdr1qwxa9asMZ9//rkZOHCgKVSokMsfgpfjzV+2xYoVy/Yw1379+ply5cqZH374wePQvXPnTufzokWLuoS2vXv3erxX/8SJE6ZLly7mpptuMps3bzZ+fn5X/AfWhb13ZcuWzfJHvCe9lSxZ0qxfv94Yc37DRXZ/YBUqVMij3rLbmr9v3z4zYsQI5xZydxQqVMjlkDc/Pz+XP5L27t1rChcu7FatyMhI52G5xpzfG2yz2Ux6eroxxpg9e/Z49PMsVKjQJcPTb7/95vH7ltN3wdOVS9myZV0OZ7zwh1DNmjXN33//7fGKpXjx4s7vVkZGhrHb7S71ExISzHXXXedWrT59+piaNWtm+a56I2zccMMNWfaILF++3O0QHxwcbDZt2mSMOf9duPD/C3bu3On25+3i3pKSksz48eNNlSpVjN1uN3Xr1jXTpk1z+5SG7L4L//787dmzx+3eChcu7LIn6syZM8bPz8/5x99nn31moqKi3KpVsmRJ89133+U4/ttvvzUlS5Z0q5Yx53/vjh8/3nz33XfZPqZPn+7R74+LD/9MTU01sbGxpmnTpmb37t0efQ8u/hkULVrUZR2xf/9+ExAQ4Ha9CRMmmIiICJejJ/7L9+DCOqFUqVIuvyeNOf+70t3fR02bNjUvv/yyMcaYBg0aZNnQvmDBArc3LmS3Pjh16pSZNWuWady4sbHb7W5/1owxJjw83Lm+On78uLHZbC5/RP/yyy8mPDzcrVqhoaEu73V6erqx2+3OU2h27drl0c+zoIQNb258Msa7G6C8ufHJmGt3A5Q3Nz4Z490NUN5cJ3hzfWCM99cJ1xpCdz700UcfmZiYGOPr6+sMBb6+viYmJsbMmzfPo1ply5Y1n332WY7jN27c6PYXoG7dumbWrFnZjuvXr58JCQnx6Mt00003mSVLljifb9682eWQyx9++MGjPXL/9uGHH5rSpUsbu91+xX9g1ahRw9SqVcsULVrULFiwwGX8999/73YI6ty5s+nZs6cxxpj777/fPPfccy7jX3zxRVOjRg2PervUIXQOh8PtlUt0dLTzZ/Dnn38au91uPv74Y+f4L7/80u0/2AYNGmSqV69ulixZYlauXGmaNGliGjdu7By/dOlSU7FiRbdqGWNMmTJlLnmo8RdffGHKlCnjdr2SJUuad9991+zduzfbx5dffun257dIkSJZDu/LzMw0bdq0MTfddJP57bffPPou/HsFb0zWDVD79u3zaIPFwoULTUREhJk8ebJzmDfCRlhYWLZhw90/nO+55x7nXpD4+Pgsh7lPnz7dVK5c2aPesvsu/PDDD6Zr166mSJEipkiRIm7VurDh0BhjDh48aGw2m/nyyy+d47/77jtTrlw5t2qVLVvW5XSAf/75x9hsNucGgN27d7v9nj366KMmMjLSLFy40OWoj5SUFLNw4UITFRVl+vfv71YtY4xp3LixGT9+fI7jf/31V7f3yN1www0u79EFJ06cMLGxsebmm2/26HtQsWJFl3Dx1ltvuWw0SUhIcDvwXbBx40ZTrVo107t3b3Py5Mn/9D3o06ePeeyxx0xYWFiW37EJCQmmVKlSbtVatWqVCQ4ONiNGjDCTJ082pUqVMs8995yZM2eOGT58uAkJCbnkz+jf/r3nMTs7duxwOW3rcjp37mxiYmLMBx98YO6++24THx9v6tevb7Zu3Wq2bdtmGjVq5Pbe5LZt25p27dqZtLQ0k5GRYQYPHuxy5NSaNWs8+nkWlLDh7Y1PxnhvA5Q3Nz4Zc+1ugPLmxidjvLsBypvrBG+uD4zx/jrhWkPozscyMjLMoUOHzKFDhzy6WNG/3X333eb555/PcbwnX6gXX3zReYhkdvr27evRl3Pq1Klm8eLFOY4fNmyYM6xeiQMHDpjPPvvMpKWleTzvyJEjXR4XXzTjiSeeMB07dnSr1sGDB01UVJS5/fbbzZAhQ0yhQoXMrbfeah5++GFz++23G39//2x/SeUkKirqis/Xu9hzzz1nQkNDTa9evUx0dLQZOnSoKV++vJk6dap5++23TURERJbDvXJy4sQJ0759e+fGogYNGrj8EfL111+7BPrLef75503x4sXNhAkTzKZNm0xiYqJJTEw0mzZtMhMmTDAlSpRw+xBdY4xp1qyZGT16dI7jPfku1KhRI8uGGGP+L3iXL1/eoxVLlSpVXK5HsHjxYucRAsac/+PU3cB3wV9//WWaNm1qmjdvbg4fPvyfwkaLFi1M27ZtTfHixbNsCFmzZo3bp4H88ccfpmTJkqZLly5m9OjRpmjRoqZz585m7NixpkuXLiYgIMC8//77bvd2ucCRkpKS5XSOnPTr189UrlzZjBkzxtSrV8907drVVKlSxSxZssQsXbrU1KhRw/To0cOtWl27djWNGjUyW7duNbt373aen3jBd9995/bpKadPnzaPPPKI8ff3N3a73QQGBprAwEBjt9uNv7+/6du3rzl9+rRbtYwxZtq0aZc8pz8xMdHl2gyXMmDAgBwDWGpqqomJifHoe9CnTx8zffr0HMePGzfOtGjRwu16F6Snp5s+ffqYypUrGx8fnyv6HjRq1MjlIp0X9zl69GjTqFEjt+utWrXK1K9fP8tRN9ddd51H5zlfbiOspxITE82dd95pihYtauLj401ycrLp37+/ywU8/x0AL2XXrl2mYsWKxtfX1/j5+ZmQkBDn9U2MOX/KhieHIheUsGHFxidjvLMBypsbn4y5djdAeXPjkzHe3QCV0zrBZrN5vE7w5vrAGO+vE641hG5c0g8//OCyN/liaWlpl9xyDO/4559/zNNPP22qVatmAgMDjb+/v4mMjDQPPPCAWbduXa71de7cOTN27FjTqlUr8+KLLxqHw2E+/PBDExERYUqWLGm6devm8UaLU6dOeXQhlUt56aWXTJkyZVwOBbTZbKZMmTJur4gvWLhwoZk9e3aO448fP25mzJjhVq2nnnoqx/PJMzMzzT333OPRH2wjR4685FXsn3nmGXPvvfe6Xe8Ch8NhXnzxRefFWq4kbHTr1s3lcfHRNk8++aSJj493u97OnTtNx44dTbFixZxBw8/PzzRo0MB8+umnHvXmzcCRlpZmHn74YVO9enXTu3dvc+bMGfPKK68Yf39/Y7PZTOPGjd1+raSkJGegstvtJjIy0uWw2Pnz55s33njDo/5SUlLMypUrzdy5c83cuXPNypUrs73ewdV0/PjxLHu6/i01NdWr65fdu3e73DHDU59//rkZPHiwV0PqBbt27TIHDhzweL4jR46YNWvWmFWrVrkc7eKuvXv3Znu3E2/btWtXlqPR3HHy5Enz9ddfm0WLFv3nq257cwPUtGnTLrlxIzfDhlUbn4z57xugvL3xyZhrcwPUpTY+2Ww2jzY+GeP9DVDGnF8nrFixwrlOWLFihdfWCVf6OyWndcKFet5eJ1xt3KcbQL63Z88el3tRunsPW6ucPXtW6enpCgoKynH8wYMHvXIvYElKT0+Xj4+PAgICrmj+hIQE/fTTT+rSpYuKFy/ulZ4uOHnypHx8fBQYGOjRfMYYHTlyRA6HQ6VKlXLes/hac/r0aWVmZqpYsWIez7tjxw6dOXNGVapUka+vrwXdAQVPamqqEhISXNYJtWvXzvH38dXwzz//6NChQ7rxxhuzHX/ixAlt2LBBjRo1+s+vtWfPHgUGBqpMmTJXXOOLL77Qt99+q2HDhiksLOw/93TB7t275e/vr3Llynk879GjR7V79245HA6VKVNGUVFRHs2/b98+lS9fXjabzePXdtfu3buVnp5+Rb/T09PT9fPPP+vMmTOqX7++SpUq5dXe/P39tWnTJlWtWvWaqmVFvdyS9c7jAJDPREdHKzY2VrGxsc7AfeDAAfXo0cNrr+FJPV9f30v+gXf48GGNGjXKW63p77//Vt++fa94/tq1a2vQoEEqXry419+348eP69FHH/V4PpvNptKlS6tMmTLOwJ2bP9OcBAYGqlixYldUq3LlyqpevXqWP848rXXq1Cn99NNP+uOPP7KMO336tGbNmuVRX96sR2+531tBWU5J2rp1qz755BOVKVNGnTp1Uq1atfTxxx9r8ODBWrlypce13n//fW3btk2StG3bNvXt21c9evTwuFbx4sVlt9tzrLdu3TqPAveletuzZ4/Hgfvietdff71OnTqloUOHXvH7tn379iy97d271+PAfaHe8ePHFRMTo+LFi2v8+PEe/xwiIyO1bds2r/1Ms1vOV155RRMmTNAPP/zgUS3p/EaBv/76S5UqVVKpUqWuuLchQ4Zk+zh37pxeeukl5/OrXcuKetecXN7TDgC5wtP7qF7NevSW+7W8XS+3am3fvt15H2K73W5uv/12c/DgQed4T6+Un129fx+y7Uk9b9ait9yvda33tmTJEuPv729KlChhAgMDzZIlS0xoaKiJi4szTZs2NT4+Pi7Xxrhategt//V2LS+nzWYzNWvWdDnMv3HjxsZms5m6deuaxo0bmyZNmlz1WlbUu9ZweDmAfOmLL7645Pjdu3fr8ccf17lz5656PXqjt6tVq23btsrMzNSMGTOUnJyswYMH648//tB3332n8uXLKykpSWXLlnX7PfNmPXrL/d4KynJKUoMGDdS0aVONGTNGH330kR599FH17dtXY8eOlSQNGzZMCQkJ+uabb65qLXrLf71dy8v50ksvadq0aXrnnXfUtGlT53A/Pz9t2rRJ1apVc6snb9eyot41J7dTPwBYwZv3mPd2PXqjt6tVKywszOX+sA6HwzzyyCOmfPnyZteuXR7vLfRmPXrL/d4KynIac/42Xzt27DDGnL8IqK+vr8sFCjdv3uz2nRS8WYve8l9v1/JyGnP+lmXXX3+9efzxx513N7rSO5R4s5YV9a4lnNMNIF8qU6aMFi5cKIfDke1jw4YNuVaP3ujtatU6deqUyznhNptNU6dO1d13361GjRrpzz//dLuWt+vRW+73VlCW8981JMlutyswMFDBwcHOccWKFVNKSkqu1KK3/NfbtbycdevWVUJCgo4ePao6depoy5YtV3wBOW/WsqLetYTQDSBfql27thISEnIcb7PZZDw4u8ab9eiN3q5WrSpVqmj9+vVZhk+ZMkWtW7fWPffc41YdK+rRW+73VlCWU5KioqK0Y8cO5/PVq1erfPnyzuf79+93+wJj3qxFb/mvt2t5OS8oWrSoZs6cqWHDhikuLs7t0zSsrmVFvWsFoRtAvvTkk0+qQYMGOY6vVKmSvv3221ypR2/0drVqtW3bVh9++GG246ZMmaJOnTp5tKHCm/XoLfd7KyjLKUl9+/Z1+eP94jsDLFmyxOU80qtVi97yX2/X8nJerGPHjlq/fr0WLlz4n29T6s1aVtTLbVxIDQAAAAAAi7CnGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAyEe6desmm82W5bFz587/XHvGjBkKCQn5700CAFCA+F5+EgAAkJc0b95c77//vsuw0NDQXOome5mZmfLz88vtNgAAsBx7ugEAyGcCAgIUHh7u8vDx8dHnn3+uW265RYGBgapQoYJGjRqls2fPOuebMGGCatSooSJFiigiIkKPPvqo0tLSJEnfffedunfvrpSUFOfe85EjR0qSbDabPvvsM5ceQkJCNGPGDEnS3r17ZbPZNG/ePDVq1EiBgYGaM2eOJOmdd95R1apVFRgYqCpVquitt95y1sjIyFD//v1VpkwZBQYGKjIyUuPGjbPujQMAwALs6QYAoAD48ccf1aVLF73xxhu67bbbtGvXLvXu3VuSNGLECEmS3W7XG2+8oejoaO3evVuPPvqonnrqKb311ltq0KCBJk6cqOHDh2v79u2SpKJFi3rUw9ChQ/Xaa6+pVq1azuA9fPhwTZkyRbVq1dLGjRv18MMPq0iRIurataveeOMNffHFF/r4449Vvnx5HThwQAcOHPDuGwMAgMUI3QAA5DOLFy92CcR33XWX/vnnHw0dOlRdu3aVJFWoUEGjR4/WU0895QzdgwcPds4TFRWlMWPG6JFHHtFbb70lf39/BQcHy2azKTw8/Ir6Gjx4sO69917n8xEjRui1115zDouOjtYff/yh//3vf+ratav279+vypUr69Zbb5XNZlNkZOQVvS4AALmJ0A0AQD7TpEkTTZ061fm8SJEiuummm/Tzzz9r7NixzuHnzp3T6dOnlZ6ersKFC2v58uUaN26ctm3bptTUVJ09e9Zl/H9Vp04d5/9PnjypXbt2qWfPnnr44Yedw8+ePavg4GBJ5y8Kd+edd+qGG25Q8+bN1apVKzVr1uw/9wEAwNVE6AYAIJ8pUqSIKlWq5DIsLS1No0aNctnTfEFgYKD27t2rVq1aqW/fvho7dqxKlCihn376ST179lRGRsYlQ7fNZpMxxmVYZmZmtn39ux9Jmj59umJiYlym8/HxkSTdcsst2rNnj5YsWaLly5erffv2iouL04IFCy7zDgAAcO0gdAMAUADccsst2r59e5YwfkFCQoIcDodee+012e3nr7P68ccfu0zj7++vc+fOZZk3NDRUhw8fdj7fsWOH0tPTL9lP6dKlVbZsWe3evVsPPvhgjtMFBQWpQ4cO6tChg+677z41b95cx48fV4kSJS5ZHwCAawWhGwCAAmD48OFq1aqVypcvr/vuu092u12bNm3Sli1bNGbMGFWqVEmZmZmaPHmy7r77bv388896++23XWpERUUpLS1NK1as0M0336zChQurcOHCatq0qaZMmaLY2FidO3dOTz/9tFu3Axs1apQGDhyo4OBgNW/eXGfOnNH69ev1zz//aMiQIZowYYLKlCmjWrVqyW63a/78+QoPD+de4QCAPIVbhgEAUADEx8dr8eLF+uabb1S3bl3Vr19fr7/+uvPiZDfffLMmTJig8ePHq3r16pozZ06W23M1aNBAjzzyiDp06KDQ0FC9/PLLkqTXXntNERERuu222/TAAw/oiSeecOsc8F69eumdd97R+++/rxo1aqhRo0aaMWOGoqOjJUnFihXTyy+/rDp16qhu3brau3evvvrqK+eeeAAA8gKbufgkLAAAAAAA4BVsKgYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACzy/wACtUrtzqn8KQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def elastic_net_search(X_train, y_train, X_test, y_test, threshold=0.5):\n",
    "    # Setup ElasticNetCV with more iterations\n",
    "    model = ElasticNetCV(cv=5, l1_ratio=np.linspace(0.01, 1, 100), alphas=np.logspace(-6, 2, 100),\n",
    "                         max_iter=5000, tol=0.0001, random_state=42)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Binarize predictions based on a threshold\n",
    "    y_pred_binarized = (y_pred > threshold).astype(int)\n",
    "    \n",
    "    # Calculating Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_binarized)\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'best_lambda': model.alpha_,\n",
    "        'best_l1_ratio': model.l1_ratio_\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "results = elastic_net_search(X_train, y_train, X_test, y_test)\n",
    "print(results)\n",
    "\n",
    "# Plotting coefficients of the best model\n",
    "best_model = ElasticNetCV(cv=5, l1_ratio=results['best_l1_ratio'], alphas=[results['best_lambda']],\n",
    "                          max_iter=5000, tol=0.01, random_state=42)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "coefficients = best_model.coef_\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(coefficients, marker='o', linestyle='none')\n",
    "plt.title('Coefficients of the Best Model')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.xticks(ticks=np.arange(len(coefficients)), rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79b8eb-e6b3-482b-ac88-a8d31933e90f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SVM w RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d1ba3f-5302-4e44-9f43-0025b92c9981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM with RBF kernel: 0.10439247005134056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM with RBF kernel\n",
    "svm_model = SVC(kernel='rbf', gamma='scale')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of SVM with RBF kernel: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70981931-1d4e-4cff-8840-c531352ffdfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d3bd58-c84d-4834-8650-24d35ba8931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: -0.018451529504223303\n",
      "Epoch 1, Loss: -0.018451529504223303, Val Accuracy: 7.64%\n",
      "Epoch 2, Loss: -2.649070114439184, Val Accuracy: 9.13%\n",
      "Epoch 3, Loss: -5.160258707133207, Val Accuracy: 9.58%\n",
      "Epoch 4, Loss: -7.578180144049904, Val Accuracy: 9.58%\n",
      "Epoch 5, Loss: -9.927314871007747, Val Accuracy: 9.58%\n",
      "Epoch 6, Loss: -12.220458056709983, Val Accuracy: 9.58%\n",
      "Epoch 7, Loss: -14.490540677850897, Val Accuracy: 9.58%\n",
      "Epoch 8, Loss: -16.747704219818115, Val Accuracy: 9.58%\n",
      "Epoch 9, Loss: -18.964626919139516, Val Accuracy: 9.58%\n",
      "Epoch 10, Loss: -21.19280053919012, Val Accuracy: 9.58%\n"
     ]
    }
   ],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)  # Output is a single value\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Model setup\n",
    "model = LinearRegressionModel(input_dim=43)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target.view(-1, 1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "    # Calculate Accuracy on validation set after each epoch\n",
    "    val_accuracy = calculate_accuracy(model, val_loader)\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}, Val Accuracy: {val_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb96245e-2fa6-43ce-baac-b202c1bbc4bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f6c6544-b954-4227-ac6d-98e1071117d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 3 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4932\\2345940893.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1179\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3058\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3059\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 3 is out of bounds."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "def calculate_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "input_dim = 43  # Number of input features\n",
    "num_classes = 2  # Number of output classes\n",
    "\n",
    "nn_model = SimpleNN(input_dim, num_classes)\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    nn_model.train()\n",
    "    total_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = nn_model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculate Accuracy on validation set after each epoch\n",
    "    val_accuracy = calculate_accuracy(nn_model, val_loader)\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}, Val Accuracy: {val_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a66f71-be4c-40f5-869e-2a8982838b85",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transformer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c428d33e-69a4-403e-a658-ca0fc1bdafb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raywz\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Validation Accuracy: 9.58%\n",
      "Epoch [2/10], Validation Accuracy: 9.58%\n",
      "Epoch [3/10], Validation Accuracy: 9.58%\n",
      "Epoch [4/10], Validation Accuracy: 9.58%\n",
      "Epoch [5/10], Validation Accuracy: 9.58%\n",
      "Epoch [6/10], Validation Accuracy: 9.58%\n",
      "Epoch [7/10], Validation Accuracy: 9.58%\n",
      "Epoch [8/10], Validation Accuracy: 9.58%\n",
      "Epoch [9/10], Validation Accuracy: 9.58%\n",
      "Epoch [10/10], Validation Accuracy: 9.58%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# Define the transformer model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, num_classes):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        encoder_layers = TransformerEncoderLayer(input_dim, num_heads, hidden_dim)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define hyperparameters\n",
    "input_dim = 43\n",
    "hidden_dim = 128\n",
    "num_layers = 1\n",
    "num_heads = 1\n",
    "num_classes = 1\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create an instance of the transformer model\n",
    "model = TransformerModel(input_dim, hidden_dim, num_layers, num_heads, num_classes).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.unsqueeze(1)  # Add an extra dimension for sequence length\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.squeeze(), target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.unsqueeze(1)  # Add an extra dimension for sequence length\n",
    "            output = model(data)\n",
    "            predicted = torch.round(torch.sigmoid(output)).squeeze()\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038185d-c5e0-453e-af52-5dfd26be28a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
